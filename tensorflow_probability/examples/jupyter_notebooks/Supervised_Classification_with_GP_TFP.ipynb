{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Supervised_Classification_with_GP_TFP.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "yp-MLjB_WtvQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2018 The TensorFlow Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "metadata": {
        "id": "7wyfmwIvWtig",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\"); { display-mode: \"form\" }\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E2BesV19Rm8n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Supervised Learning (Classification) with TFP\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://drive.google.com/file/d/1G1ba3qrgvwxVLnIJTY0s9CfEvVh9PdbG/view?usp=sharing\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "\n",
        "Original content [this Repository](https://github.com/blei-lab/edward), created by [the Blei Lab](http://www.cs.columbia.edu/~blei/)\n",
        "\n",
        "Ported to Tensorflow Probability by Matthew McAteer ([`@MatthewMcAteer0`](https://twitter.com/MatthewMcAteer0)), with help from the TFP team at  Google ([`tfprobability@tensorflow.org`](mailto:tfprobability@tensorflow.org)).\n",
        "\n",
        "---\n",
        "\n",
        ">[Dependencies & Prerequisites](#scrollTo=2ZtWUjXYRXQi)\n",
        "\n",
        ">[Introduction](#scrollTo=2ZtWUjXYRXQi)\n",
        "\n",
        ">>[Data](#scrollTo=2ZtWUjXYRXQi)\n",
        "\n",
        ">>[Model](#scrollTo=2ZtWUjXYRXQi)\n",
        "\n",
        ">>[Inference](#scrollTo=2ZtWUjXYRXQi)\n",
        "\n",
        ">>[Criticism](#scrollTo=2ZtWUjXYRXQi)\n",
        "\n",
        ">[References](#scrollTo=2ZtWUjXYRXQi)"
      ]
    },
    {
      "metadata": {
        "id": "nvFPAsJ-bfth",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Dependencies & Prerequisites"
      ]
    },
    {
      "metadata": {
        "id": "2jobvD7RVDiw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 install -q tfp-nightly\n",
        "!pip3 install -q observations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1s77KCLRRm8n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "\n",
        "import time\n",
        "from observations import karate\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Ellipse\n",
        "import seaborn as sns\n",
        "from IPython.core.pylabtools import figsize\n",
        "\n",
        "import tensorflow as tf                            # importing Tensorflow\n",
        "\n",
        "import tensorflow_probability as tfp               # Tensorflow probability\n",
        "from tensorflow_probability import edward2 as ed   # Edwardlib extension\n",
        "\n",
        "tfd = tf.contrib.distributions             # Basic probability distribution toolkit\n",
        "tfb = tf.contrib.distributions.bijectors   # and their modifiers\n",
        "\n",
        "dtype = np.float32    # A tool to make sure we're inputing the right data type\n",
        "\n",
        "%matplotlib inline\n",
        "plt.style.use('fivethirtyeight')        # Styling plots like FiveThirtyEight\n",
        "\n",
        "%config InlineBackend.figure_format='retina' # improves resolution of plots\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')       # Some python imports raise depreciation warnings\n",
        "\n",
        "## from edward.models import Bernoulli, MultivariateNormalTriL, Normal\n",
        "# from edward.util import rbf\n",
        "from observations import crabs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b_MQFBz1kWTd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def session_options(enable_gpu_ram_resizing=True, enable_xla=True):\n",
        "    \"\"\"\n",
        "    Allowing the notebook to make use of GPUs if they're available.\n",
        "    \n",
        "    XLA (Accelerated Linear Algebra) is a domain-specific compiler for linear \n",
        "    algebra that optimizes TensorFlow computations.\n",
        "    \"\"\"\n",
        "    config = tf.ConfigProto()\n",
        "    config.log_device_placement = True\n",
        "    if enable_gpu_ram_resizing:\n",
        "        # `allow_growth=True` makes it possible to connect multiple colabs to your\n",
        "        # GPU. Otherwise the colab malloc's all GPU ram.\n",
        "        config.gpu_options.allow_growth = True\n",
        "    if enable_xla:\n",
        "        # Enable on XLA. https://www.tensorflow.org/performance/xla/.\n",
        "        config.graph_options.optimizer_options.global_jit_level = (\n",
        "            tf.OptimizerOptions.ON_1)\n",
        "    return config\n",
        "\n",
        "\n",
        "def reset_sess(config=None):\n",
        "    \"\"\"\n",
        "    Convenience function to create the TF graph & session or reset them.\n",
        "    \"\"\"\n",
        "    if config is None:\n",
        "        config = session_options()\n",
        "    global sess\n",
        "    tf.reset_default_graph()\n",
        "    try:\n",
        "        sess.close()\n",
        "    except:\n",
        "        pass\n",
        "    sess = tf.InteractiveSession(config=config)\n",
        "\n",
        "    \n",
        "def evaluate(tensors):\n",
        "    \"\"\"\n",
        "    A \"Universal\" evaluate function for both running either Graph mode (default)\n",
        "    or Eager mode (https://www.tensorflow.org/guide/eager) in Tensorflow.\n",
        "    \"\"\"\n",
        "    if context.executing_eagerly():\n",
        "        return (t.numpy() for t in tensprs)\n",
        "    with tf.get_default_session() as sess:\n",
        "        return sess.run(tensors)\n",
        "\n",
        "reset_sess()\n",
        "\n",
        "\n",
        "def strip_consts(graph_def, max_const_size=32):\n",
        "  \"\"\"\n",
        "  Strip large constant values from graph_def.\n",
        "  \"\"\"\n",
        "  strip_def = tf.GraphDef()\n",
        "  for n0 in graph_def.node:\n",
        "    n = strip_def.node.add()\n",
        "    n.MergeFrom(n0)\n",
        "    if n.op == 'Const':\n",
        "      tensor = n.attr['value'].tensor\n",
        "      size = len(tensor.tensor_content)\n",
        "      if size > max_const_size:\n",
        "        tensor.tensor_content = bytes(\"<stripped %d bytes>\"%size, 'utf-8')\n",
        "  return strip_def\n",
        "\n",
        "\n",
        "def draw_graph(model, *args, **kwargs):\n",
        "  \"\"\"\n",
        "  Visualize TensorFlow graph.\n",
        "  \"\"\"\n",
        "  graph = tf.Graph()\n",
        "  with graph.as_default():\n",
        "    model(*args, **kwargs)\n",
        "  graph_def = graph.as_graph_def()\n",
        "  strip_def = strip_consts(graph_def, max_const_size=32)\n",
        "  code = \"\"\"\n",
        "      <script>\n",
        "        function load() {{\n",
        "          document.getElementById(\"{id}\").pbtxt = {data};\n",
        "        }}\n",
        "      </script>\n",
        "      <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
        "      <div style=\"height:600px\">\n",
        "        <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
        "      </div>\n",
        "  \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
        "\n",
        "  iframe = \"\"\"\n",
        "      <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
        "  \"\"\".format(code.replace('\"', '&quot;'))\n",
        "  IPython.display.display(IPython.display.HTML(iframe))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rLgn7MGNVLk-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "In supervised learning, the task is to infer hidden structure from labeled data, comprised of training examples $\\{(x_n, y_n)\\}$. Classification means the output $y$ takes discrete values."
      ]
    },
    {
      "metadata": {
        "id": "rETRud5cRm8q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data\n",
        "\n",
        "Use the\n",
        "[crabs data set](https://stat.ethz.ch/R-manual/R-devel/library/MASS/html/crabs.html),\n",
        "which consists of morphological measurements on a crab species. We\n",
        "are interested in predicting whether a given crab has the color form\n",
        "blue (encoded as 0) or orange (encoded as 1). We use all the numeric features\n",
        "in the dataset."
      ]
    },
    {
      "metadata": {
        "id": "-gkq_TOLRm8r",
        "colab_type": "code",
        "colab": {},
        "outputId": "85977cc1-4c55-4580-936f-4dcd6c66c52c"
      },
      "cell_type": "code",
      "source": [
        "# ed.set_seed(42)\n",
        "\n",
        "data, metadata = crabs(\"~/data\")\n",
        "X_train = data[:100, 3:]\n",
        "y_train = data[:100, 1]\n",
        "\n",
        "N = X_train.shape[0]  # number of data points\n",
        "D = X_train.shape[1]  # number of features\n",
        "\n",
        "print(\"Number of data points: {}\".format(N))\n",
        "print(\"Number of features: {}\".format(D))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of data points: 100\n",
            "Number of features: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cfs4k7_gRm8u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model\n",
        "\n",
        "A Gaussian process is a powerful object for modeling nonlinear\n",
        "relationships between pairs of random variables. It defines a distribution over\n",
        "(possibly nonlinear) functions, which can be applied for representing\n",
        "our uncertainty around the true functional relationship.\n",
        "Here we define a Gaussian process model for classification\n",
        "(Rasumussen & Williams, 2006).\n",
        "\n",
        "Formally, a distribution over functions $f:\\mathbb{R}^D\\to\\mathbb{R}$ can be specified\n",
        "by a Gaussian process\n",
        "$$\n",
        "\\begin{align*}\n",
        "  p(f)\n",
        "  &=\n",
        "  \\mathcal{GP}(f\\mid \\mathbf{0}, k(\\mathbf{x}, \\mathbf{x}^\\prime)),\n",
        "\\end{align*}\n",
        "$$\n",
        "whose mean function is the zero function, and whose covariance\n",
        "function is some kernel which describes dependence between\n",
        "any set of inputs to the function.\n",
        "\n",
        "Given a set of input-output pairs\n",
        "$\\{\\mathbf{x}_n\\in\\mathbb{R}^D,y_n\\in\\mathbb{R}\\}$,\n",
        "the likelihood can be written as a multivariate normal\n",
        "\n",
        "\\begin{align*}\n",
        "  p(\\mathbf{y})\n",
        "  &=\n",
        "  \\text{Normal}(\\mathbf{y} \\mid \\mathbf{0}, \\mathbf{K})\n",
        "\\end{align*}\n",
        "\n",
        "where $\\mathbf{K}$ is a covariance matrix given by evaluating\n",
        "$k(\\mathbf{x}_n, \\mathbf{x}_m)$ for each pair of inputs in the data\n",
        "set.\n",
        "\n",
        "The above applies directly for regression where $\\mathbb{y}$ is a\n",
        "real-valued response, but not for (binary) classification, where $\\mathbb{y}$\n",
        "is a label in $\\{0,1\\}$. To deal with classification, we interpret the\n",
        "response as latent variables which is squashed into $[0,1]$. We then\n",
        "draw from a Bernoulli to determine the label, with probability given\n",
        "by the squashed value.\n",
        "\n",
        "Define the likelihood of an observation $(\\mathbf{x}_n, y_n)$ as\n",
        "\n",
        "\\begin{align*}\n",
        "  p(y_n \\mid \\mathbf{z}, x_n)\n",
        "  &=\n",
        "  \\text{Bernoulli}(y_n \\mid \\text{logit}^{-1}(\\mathbf{x}_n^\\top \\mathbf{z})).\n",
        "\\end{align*}\n",
        "\n",
        "Define the prior to be a multivariate normal\n",
        "\n",
        "\\begin{align*}\n",
        "  p(\\mathbf{z})\n",
        "  &=\n",
        "  \\text{Normal}(\\mathbf{z} \\mid \\mathbf{0}, \\mathbf{K}),\n",
        "\\end{align*}\n",
        "\n",
        "with covariance matrix given as previously stated.\n",
        "\n",
        "Let's build the model in Edward. We use a radial basis function (RBF)\n",
        "kernel, also known as the squared exponential or exponentiated\n",
        "quadratic. It returns the kernel matrix evaluated over all pairs of\n",
        "data points; we then Cholesky decompose the matrix to parameterize the\n",
        "multivariate normal distribution."
      ]
    },
    {
      "metadata": {
        "id": "LNOGQ_w_Rm8v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = tf.placeholder(tf.float32, [N, D])\n",
        "f = tfd.MultivariateNormalTriL(loc=tf.zeros(N), scale_tril=tf.cholesky(rbf(X)))\n",
        "y = tfd.Bernoulli(logits=f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bZfGJtpXRm8x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here, we define a placeholder `X`. During inference, we pass in\n",
        "the value for this placeholder according to data."
      ]
    },
    {
      "metadata": {
        "id": "w5bmYxs5Rm8x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Inference\n",
        "\n",
        "Perform variational inference.\n",
        "Define the variational model to be a fully factorized normal."
      ]
    },
    {
      "metadata": {
        "id": "GDH76LuYRm8y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "qf = tfd.Normal(loc=tf.get_variable(\"qf/loc\", [N]),\n",
        "            scale=tf.nn.softplus(tf.get_variable(\"qf/scale\", [N])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WPuUT_JjRm80",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Run variational inference for `5000` iterations."
      ]
    },
    {
      "metadata": {
        "id": "a0wO7y06Rm81",
        "colab_type": "code",
        "colab": {},
        "outputId": "67c8b5e7-b570-4b0b-a6ca-20f0843c6bac"
      },
      "cell_type": "code",
      "source": [
        "inference = ed.KLqp({f: qf}, data={X: X_train, y: y_train})\n",
        "inference.run(n_iter=5000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000/5000 [100%] ██████████████████████████████ Elapsed: 9s | Loss: 78.369\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jf5WinRKlhuu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Visualizing the graph we've constructed\n",
        "# draw_graph(linear_mixed_effects_model, features_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ev3Ct4AaRm84",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this case\n",
        "`KLqp` defaults to minimizing the\n",
        "$\\text{KL}(q\\|p)$ divergence measure using the reparameterization\n",
        "gradient.\n",
        "For more details on inference, see the [$\\text{KL}(q\\|p)$ tutorial](/tutorials/klqp).\n",
        "(This example happens to be slow because evaluating and inverting full\n",
        "covariances in Gaussian processes happens to be slow.)"
      ]
    },
    {
      "metadata": {
        "id": "PAs0LelnRm84",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Reference\n",
        "\n",
        "1. Rasmussen, C. E., & Williams, C. (2006). [Gaussian processes for machine learning](http://www.newton.ac.uk/files/seminar/20070809140015001-150844.pdf). MIT Press.\n",
        "2. [Supervised Classification](http://edwardlib.org/tutorials/supervised-classification)"
      ]
    },
    {
      "metadata": {
        "id": "mUQ0cTQbRm85",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.core.display import HTML\n",
        "def css_styling():\n",
        "    styles = open(\"../styles/custom.css\", \"r\").read()\n",
        "    return HTML(styles)\n",
        "css_styling()\n",
        "\n",
        "#  \"#F15854\",  // red\n",
        "#  \"#5DA5DA\",  // blue\n",
        "#  \"#FAA43A\",  // orange\n",
        "#  \"#60BD68\",  // green\n",
        "#  \"#F17CB0\",  // pink\n",
        "#  \"#B2912F\",  // brown\n",
        "#  \"#B276B2\",  // purple\n",
        "#  \"#DECF3F\",  // yellow\n",
        "#  \"#4D4D4D\",  // gray\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}