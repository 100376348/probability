{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sigmoid_Beleif_Network_TFP.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "AxDfcPsLtXVc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2018 The TensorFlow Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "metadata": {
        "id": "Cs7i1ZEUtXsy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\"); { display-mode: \"form\" }\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XPFoRUIPRTaD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Sigmoid Beleif Network with TFP\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://drive.google.com/file/d/1-lcrM5lV0TUmJJBRXfXajYDPGswAXkzd/view?usp=sharing\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "Original content [this Repository](https://github.com/blei-lab/edward/blob/master/examples/sigmoid_belief_network.py), created by [the Blei Lab](http://www.cs.columbia.edu/~blei/)\n",
        "\n",
        "Ported to Tensorflow Probability by Matthew McAteer ([`@MatthewMcAteer0`](https://twitter.com/MatthewMcAteer0)), with help from the TFP team at  Google ([`tfprobability@tensorflow.org`](mailto:tfprobability@tensorflow.org)).\n",
        "\n",
        "---\n",
        "\n",
        ">[Dependencies & Prerequisites](#scrollTo=2ZtWUjXYRXQi)\n",
        "\n",
        ">[Introduction](#scrollTo=2ZtWUjXYRXQi)\n",
        "\n",
        ">>[Data](#scrollTo=2ZtWUjXYRXQi)\n",
        "\n",
        ">>[Model](#scrollTo=2ZtWUjXYRXQi)\n",
        "\n",
        ">>[Inference](#scrollTo=2ZtWUjXYRXQi)\n",
        "\n",
        ">>[Criticism](#scrollTo=2ZtWUjXYRXQi)\n",
        "\n",
        ">[References](#scrollTo=2ZtWUjXYRXQi)"
      ]
    },
    {
      "metadata": {
        "id": "jEui6GrPbbdz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Dependencies & Prerequisites"
      ]
    },
    {
      "metadata": {
        "id": "hoogfWvGxsZ1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 install -q tfp-nightly\n",
        "!pip3 install -q observations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MelbdC_ktc_H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "# import edward as ed\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "# from edward.models import Bernoulli\n",
        "# from edward.util import Progbar\n",
        "from observations import caltech101_silhouettes\n",
        "from scipy.misc import imsave"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SvvztbdFkkPE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def session_options(enable_gpu_ram_resizing=True, enable_xla=True):\n",
        "    \"\"\"\n",
        "    Allowing the notebook to make use of GPUs if they're available.\n",
        "    \n",
        "    XLA (Accelerated Linear Algebra) is a domain-specific compiler for linear \n",
        "    algebra that optimizes TensorFlow computations.\n",
        "    \"\"\"\n",
        "    config = tf.ConfigProto()\n",
        "    config.log_device_placement = True\n",
        "    if enable_gpu_ram_resizing:\n",
        "        # `allow_growth=True` makes it possible to connect multiple colabs to your\n",
        "        # GPU. Otherwise the colab malloc's all GPU ram.\n",
        "        config.gpu_options.allow_growth = True\n",
        "    if enable_xla:\n",
        "        # Enable on XLA. https://www.tensorflow.org/performance/xla/.\n",
        "        config.graph_options.optimizer_options.global_jit_level = (\n",
        "            tf.OptimizerOptions.ON_1)\n",
        "    return config\n",
        "\n",
        "\n",
        "def reset_sess(config=None):\n",
        "    \"\"\"\n",
        "    Convenience function to create the TF graph & session or reset them.\n",
        "    \"\"\"\n",
        "    if config is None:\n",
        "        config = session_options()\n",
        "    global sess\n",
        "    tf.reset_default_graph()\n",
        "    try:\n",
        "        sess.close()\n",
        "    except:\n",
        "        pass\n",
        "    sess = tf.InteractiveSession(config=config)\n",
        "\n",
        "    \n",
        "def evaluate(tensors):\n",
        "    \"\"\"\n",
        "    A \"Universal\" evaluate function for both running either Graph mode (default)\n",
        "    or Eager mode (https://www.tensorflow.org/guide/eager) in Tensorflow.\n",
        "    \"\"\"\n",
        "    if context.executing_eagerly():\n",
        "        return (t.numpy() for t in tensprs)\n",
        "    with tf.get_default_session() as sess:\n",
        "        return sess.run(tensors)\n",
        "\n",
        "reset_sess()\n",
        "\n",
        "\n",
        "def strip_consts(graph_def, max_const_size=32):\n",
        "  \"\"\"\n",
        "  Strip large constant values from graph_def.\n",
        "  \"\"\"\n",
        "  strip_def = tf.GraphDef()\n",
        "  for n0 in graph_def.node:\n",
        "    n = strip_def.node.add()\n",
        "    n.MergeFrom(n0)\n",
        "    if n.op == 'Const':\n",
        "      tensor = n.attr['value'].tensor\n",
        "      size = len(tensor.tensor_content)\n",
        "      if size > max_const_size:\n",
        "        tensor.tensor_content = bytes(\"<stripped %d bytes>\"%size, 'utf-8')\n",
        "  return strip_def\n",
        "\n",
        "\n",
        "def draw_graph(model, *args, **kwargs):\n",
        "  \"\"\"\n",
        "  Visualize TensorFlow graph.\n",
        "  \"\"\"\n",
        "  graph = tf.Graph()\n",
        "  with graph.as_default():\n",
        "    model(*args, **kwargs)\n",
        "  graph_def = graph.as_graph_def()\n",
        "  strip_def = strip_consts(graph_def, max_const_size=32)\n",
        "  code = \"\"\"\n",
        "      <script>\n",
        "        function load() {{\n",
        "          document.getElementById(\"{id}\").pbtxt = {data};\n",
        "        }}\n",
        "      </script>\n",
        "      <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
        "      <div style=\"height:600px\">\n",
        "        <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
        "      </div>\n",
        "  \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
        "\n",
        "  iframe = \"\"\"\n",
        "      <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
        "  \"\"\".format(code.replace('\"', '&quot;'))\n",
        "  IPython.display.display(IPython.display.HTML(iframe))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RIrvbqn9lqTz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Visualizing the graph we've constructed\n",
        "# draw_graph(linear_mixed_effects_model, features_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IidYCPxqRTaG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "Sigmoid belief network (Neal, 1990) trained on the Caltech 101 Silhouettes data set.\n",
        "\n",
        "Default settings take ~143s / epoch on a Titan X (Pascal). \n",
        "\n",
        "Results on epoch 100:\n",
        "- Training negative log-likelihood: 209.443\n",
        "- Test negative log-likelihood: 161.244\n",
        "- Using n_train_samples=50 converges to test NLL of 157.824."
      ]
    },
    {
      "metadata": {
        "id": "TrGOjFE_RTaJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# tf.flags.DEFINE_string(\"data_dir\", default=\"/tmp/data\", help=\"\")\n",
        "# tf.flags.DEFINE_string(\"out_dir\", default=\"/tmp/out\", help=\"\")\n",
        "# tf.flags.DEFINE_integer(\"batch_size\", default=24, help=\"Batch size during training.\")\n",
        "# tf.flags.DEFINE_list(\"hidden_sizes\", default=[300, 100, 50, 10], help=\"Hidden size per layer from bottom-up.\")\n",
        "# tf.flags.DEFINE_integer(\"n_train_samples\", default=10, help=\"Number of samples for training.\")\n",
        "# tf.flags.DEFINE_integer(\"n_test_samples\", default=1000, help=\"Number of samples to calculate test log-lik.\")\n",
        "# tf.flags.DEFINE_float(\"step_size\", default=1e-3, help=\"Learning rate step size.\")\n",
        "# tf.flags.DEFINE_integer(\"n_epoch\", default=100, help=\"\")\n",
        "# tf.flags.DEFINE_integer(\"n_iter_per_epoch\", default=10000, help=\"\")\n",
        "# FLAGS = tf.flags.FLAGS\n",
        "\n",
        "data_dir = \"/tmp/data\"\n",
        "out_dir = \"/tmp/out\"\n",
        "batch_size = 24                   # Batch size during training\n",
        "hidden_sizes = [300, 100, 50, 10] # Hidden size per layer from bottom-up\n",
        "n_train_samples = 10              # Number of samples for training\n",
        "n_test_samples = 1000             # Number of samples to calculate test log-lik\n",
        "step_size = 1e-3                  # Learning rate step size\n",
        "n_epoch = 100\n",
        "n_iter_per_epoch = 10000\n",
        "\n",
        "if not os.path.exists(out_dir):\n",
        "    os.makedirs(out_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eyvbD5BzRTaQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generator(array, batch_size):\n",
        "    \"\"\"\n",
        "    Generate batch with respect to array's first axis.\n",
        "    \"\"\"\n",
        "    start = 0  # pointer to where we are in iteration\n",
        "    while True:\n",
        "        stop = start + batch_size\n",
        "        diff = stop - array.shape[0]\n",
        "        if diff <= 0:\n",
        "            batch = array[start:stop]\n",
        "            start += batch_size\n",
        "        else:\n",
        "            batch = np.concatenate((array[start:], array[:diff]))\n",
        "            start = diff\n",
        "        yield batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VCsJoEnsRTaX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data"
      ]
    },
    {
      "metadata": {
        "id": "7uQNrShaRTaY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ed.set_seed(42)\n",
        "\n",
        "(x_train, _), (x_test, _), (x_valid, _) = caltech101_silhouettes(\n",
        "      data_dir)\n",
        "x_train_generator = generator(x_train, batch_size)\n",
        "x_ph = tf.placeholder(tf.int32, [None, 28 * 28])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CkglAhNSRTac",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model"
      ]
    },
    {
      "metadata": {
        "id": "q3UlmxDrRTae",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "s = [0] * len(hidden_sizes)\n",
        "for l in reversed(range(len(hidden_sizes))):\n",
        "    if l == len(hidden_sizes) - 1:\n",
        "          logits = tf.zeros([tf.shape(x_ph)[0], hidden_sizes[l]])\n",
        "    else:\n",
        "          logits = tf.layers.dense(tf.cast(zs[l + 1], tf.float32),\n",
        "                               hidden_sizes[l], activation=None)\n",
        "    zs[l] = tfd.Bernoulli(logits=logits)\n",
        "\n",
        "x = tfd.Bernoulli(logits=tf.layers.dense(tf.cast(zs[0], tf.float32),\n",
        "                                       28 * 28, activation=None))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2o0Ynak2RTai",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Inference"
      ]
    },
    {
      "metadata": {
        "id": "oUBo_FNERTai",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define variational model with reverse ordering as probability model:\n",
        "# if p is 15-100-300 from top-down, q is 300-100-15 from bottom-up.\n",
        "qzs = [0] * len(hidden_sizes)\n",
        "for l in range(len(hidden_sizes)):\n",
        "    if l == 0:\n",
        "          logits = tf.layers.dense(tf.cast(x_ph, tf.float32),\n",
        "                               hidden_sizes[l], activation=None)\n",
        "    else:\n",
        "          logits = tf.layers.dense(tf.cast(qzs[l - 1], tf.float32),\n",
        "                               hidden_sizes[l], activation=None)\n",
        "    qzs[l] = tfd.Bernoulli(logits=logits)\n",
        "\n",
        "inference = ed.KLqp({z: qz for z, qz in zip(zs, qzs)}, data={x: x_ph})\n",
        "optimizer = tf.train.AdamOptimizer(step_size)\n",
        "inference.initialize(optimizer=optimizer, n_samples=n_train_samples)\n",
        "\n",
        "# Build tensor for log-likelihood given one variational sample to run\n",
        "# on test data.\n",
        "x_post = tf.copy(x, {z: qz for z, qz in zip(zs, qzs)})\n",
        "x_neg_log_prob = (-tf.reduce_sum(x_post.log_prob(x_ph)) /\n",
        "                    tf.cast(tf.shape(x_ph)[0], tf.float32))\n",
        "\n",
        "\n",
        "tf.global_variables_initializer().run()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4etuen9vRTam",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()\n",
        "\n",
        "for epoch in range(n_epoch):\n",
        "    print(\"Epoch {}\".format(epoch))\n",
        "    train_loss = 0.0\n",
        "\n",
        "    pbar = Progbar(n_iter_per_epoch)\n",
        "    for t in range(1, n_iter_per_epoch + 1):\n",
        "        pbar.update(t)\n",
        "        x_batch = next(x_train_generator)\n",
        "        info_dict = inference.update(feed_dict={x_ph: x_batch})\n",
        "        train_loss += info_dict['loss']\n",
        "\n",
        "    # Print per-data point loss, averaged over training epoch.\n",
        "    train_loss /= n_iter_per_epoch\n",
        "    train_loss /= batch_size\n",
        "    print(\"Training negative log-likelihood: {:0.3f}\".format(train_loss))\n",
        "\n",
        "    test_loss = [sess.run(x_neg_log_prob, {x_ph: x_test})\n",
        "                 for _ in range(n_test_samples)]\n",
        "    test_loss = np.mean(test_loss)\n",
        "    print(\"Test negative log-likelihood: {:0.3f}\".format(test_loss))\n",
        "\n",
        "    # Prior predictive check.\n",
        "    images = sess.run(x, {x_ph: x_batch})  # feed ph to determine sample size\n",
        "    for m in range(batch_size):\n",
        "        imsave(\"{}/{}.png\".format(out_dir, m), images[m].reshape(28, 28))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2rGFv5Y2RTap",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Reference\n",
        "\n",
        "1. Sigmoid belief network (Neal, 1990)"
      ]
    },
    {
      "metadata": {
        "id": "3MHuERH0RTap",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.core.display import HTML\n",
        "def css_styling():\n",
        "    styles = open(\"../styles/custom.css\", \"r\").read()\n",
        "    return HTML(styles)\n",
        "css_styling()\n",
        "\n",
        "#  \"#F15854\",  // red\n",
        "#  \"#5DA5DA\",  // blue\n",
        "#  \"#FAA43A\",  // orange\n",
        "#  \"#60BD68\",  // green\n",
        "#  \"#F17CB0\",  // pink\n",
        "#  \"#B2912F\",  // brown\n",
        "#  \"#B276B2\",  // purple\n",
        "#  \"#DECF3F\",  // yellow\n",
        "#  \"#4D4D4D\",  // gray"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}