{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Factor_Analysis_TFP.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "XmUsCCVFsrMw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2018 The TensorFlow Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "metadata": {
        "id": "XTwv-2vpsrtC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\"); { display-mode: \"form\" }\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aQQJu6myRp2T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Factor Analysis (with TFP)\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://drive.google.com/file/d/1Ua5Y1PmN_ApurIhzGF3dcUlLbO8TbDcO/view?usp=sharing\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "Original content [this Repository](https://github.com/blei-lab/edward), created by [the Blei Lab](http://www.cs.columbia.edu/~blei/)\n",
        "\n",
        "Ported to Tensorflow Probability by Matthew McAteer ([`@MatthewMcAteer0`](https://twitter.com/MatthewMcAteer0)), with help from the TFP team at  Google ([`tfprobability@tensorflow.org`](mailto:tfprobability@tensorflow.org)).\n",
        "\n",
        "---\n",
        "\n",
        ">[Dependencies & Prerequisites](#scrollTo=2ZtWUjXYRXQi)\n",
        "\n",
        ">[Introduction](#scrollTo=2ZtWUjXYRXQi)\n",
        "\n",
        ">>[Data](#scrollTo=2ZtWUjXYRXQi)\n",
        "\n",
        ">>[Model](#scrollTo=2ZtWUjXYRXQi)\n",
        "\n",
        ">>[Inference](#scrollTo=2ZtWUjXYRXQi)\n",
        "\n",
        ">>[Criticism](#scrollTo=2ZtWUjXYRXQi)\n",
        "\n",
        ">[References](#scrollTo=2ZtWUjXYRXQi)\n"
      ]
    },
    {
      "metadata": {
        "id": "WVNxJNV4Rp2T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Dependencies & Prerequisites"
      ]
    },
    {
      "metadata": {
        "id": "SYlGKKslxPVk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 install -q tfp-nightly\n",
        "!pip3 install -q observations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K3haWCiisH_E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "# import edward as ed\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "# from edward.models import Bernoulli, Empirical, Normal\n",
        "from observations import mnist\n",
        "from scipy.misc import imsave\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mx_hxAPCku5D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def session_options(enable_gpu_ram_resizing=True, enable_xla=True):\n",
        "    \"\"\"\n",
        "    Allowing the notebook to make use of GPUs if they're available.\n",
        "    \n",
        "    XLA (Accelerated Linear Algebra) is a domain-specific compiler for linear \n",
        "    algebra that optimizes TensorFlow computations.\n",
        "    \"\"\"\n",
        "    config = tf.ConfigProto()\n",
        "    config.log_device_placement = True\n",
        "    if enable_gpu_ram_resizing:\n",
        "        # `allow_growth=True` makes it possible to connect multiple colabs to your\n",
        "        # GPU. Otherwise the colab malloc's all GPU ram.\n",
        "        config.gpu_options.allow_growth = True\n",
        "    if enable_xla:\n",
        "        # Enable on XLA. https://www.tensorflow.org/performance/xla/.\n",
        "        config.graph_options.optimizer_options.global_jit_level = (\n",
        "            tf.OptimizerOptions.ON_1)\n",
        "    return config\n",
        "\n",
        "\n",
        "def reset_sess(config=None):\n",
        "    \"\"\"\n",
        "    Convenience function to create the TF graph & session or reset them.\n",
        "    \"\"\"\n",
        "    if config is None:\n",
        "        config = session_options()\n",
        "    global sess\n",
        "    tf.reset_default_graph()\n",
        "    try:\n",
        "        sess.close()\n",
        "    except:\n",
        "        pass\n",
        "    sess = tf.InteractiveSession(config=config)\n",
        "\n",
        "    \n",
        "def evaluate(tensors):\n",
        "    \"\"\"\n",
        "    A \"Universal\" evaluate function for both running either Graph mode (default)\n",
        "    or Eager mode (https://www.tensorflow.org/guide/eager) in Tensorflow.\n",
        "    \"\"\"\n",
        "    if context.executing_eagerly():\n",
        "        return (t.numpy() for t in tensprs)\n",
        "    with tf.get_default_session() as sess:\n",
        "        return sess.run(tensors)\n",
        "\n",
        "reset_sess()\n",
        "\n",
        "\n",
        "def strip_consts(graph_def, max_const_size=32):\n",
        "  \"\"\"\n",
        "  Strip large constant values from graph_def.\n",
        "  \"\"\"\n",
        "  strip_def = tf.GraphDef()\n",
        "  for n0 in graph_def.node:\n",
        "    n = strip_def.node.add()\n",
        "    n.MergeFrom(n0)\n",
        "    if n.op == 'Const':\n",
        "      tensor = n.attr['value'].tensor\n",
        "      size = len(tensor.tensor_content)\n",
        "      if size > max_const_size:\n",
        "        tensor.tensor_content = bytes(\"<stripped %d bytes>\"%size, 'utf-8')\n",
        "  return strip_def\n",
        "\n",
        "\n",
        "def draw_graph(model, *args, **kwargs):\n",
        "  \"\"\"\n",
        "  Visualize TensorFlow graph.\n",
        "  \"\"\"\n",
        "  graph = tf.Graph()\n",
        "  with graph.as_default():\n",
        "    model(*args, **kwargs)\n",
        "  graph_def = graph.as_graph_def()\n",
        "  strip_def = strip_consts(graph_def, max_const_size=32)\n",
        "  code = \"\"\"\n",
        "      <script>\n",
        "        function load() {{\n",
        "          document.getElementById(\"{id}\").pbtxt = {data};\n",
        "        }}\n",
        "      </script>\n",
        "      <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
        "      <div style=\"height:600px\">\n",
        "        <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
        "      </div>\n",
        "  \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
        "\n",
        "  iframe = \"\"\"\n",
        "      <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
        "  \"\"\".format(code.replace('\"', '&quot;'))\n",
        "  IPython.display.display(IPython.display.HTML(iframe))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zeOTcvHfV__b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "Logistic factor analysis on MNIST. Using Monte Carlo EM, with HMC for the E-step and MAP for the M-step. We fit to just one data point in MNIST."
      ]
    },
    {
      "metadata": {
        "id": "V-4u_3FARp2U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# tf.flags.DEFINE_string(\"data_dir\", default=\"/tmp/data\", help=\"\")\n",
        "# tf.flags.DEFINE_string(\"out_dir\", default=\"/tmp/out\", help=\"\")\n",
        "# tf.flags.DEFINE_integer(\"N\", default=1, help=\"Number of data points.\")\n",
        "# tf.flags.DEFINE_integer(\"d\", default=10, help=\"Number of latent dimensions.\")\n",
        "# tf.flags.DEFINE_integer(\"n_iter_per_epoch\", default=5000, help=\"\")\n",
        "# tf.flags.DEFINE_integer(\"n_epoch\", default=20, help=\"\")\n",
        "\n",
        "# FLAGS = tf.flags.FLAGS\n",
        "\n",
        "\n",
        "data_dir = \"/tmp/data\"\n",
        "out_dir = \"/tmp/out\"\n",
        "N = 1   # Number of data points\n",
        "d = 10  # Number of latent dimensions\n",
        "n_iter_per_epoch = 5000\n",
        "n_epoch = 20\n",
        "\n",
        "if not os.path.exists(out_dir):\n",
        "    os.makedirs(out_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P0jc-3lARp2V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generative_network(z):\n",
        "    \"\"\"Generative network to parameterize generative model. It takes\n",
        "    latent variables as input and outputs the likelihood parameters.\n",
        "    logits = neural_network(z)\n",
        "    \"\"\"\n",
        "    net = tf.layers.dense(z, 28 * 28, activation=None)\n",
        "    net = tf.reshape(net, [N, -1])\n",
        "    return net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yl5jwYUgRp2X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data"
      ]
    },
    {
      "metadata": {
        "id": "69BoTcqQRp2X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ed.set_seed(42)\n",
        "\n",
        "(x_train, _), (x_test, _) = mnist(data_dir)\n",
        "x_train = x_train[:N]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jyfD6vjvRp2Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model"
      ]
    },
    {
      "metadata": {
        "id": "7qsd5L-HRp2a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "z = tfd.Normal(loc=tf.zeros([N, d]),\n",
        "             scale=tf.ones([N, d]))\n",
        "logits = generative_network(z)\n",
        "x = tfd.Bernoulli(logits=logits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iqnoQ06bRp2c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### HMC Inference"
      ]
    },
    {
      "metadata": {
        "id": "gDGr--5LRp2d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "T = .n_iter_per_epoch * n_epoch\n",
        "qz = tfd.Empirical(params=tf.get_variable(\"qz/params\", [T, N, d]))\n",
        "\n",
        "# E-Step\n",
        "inference_e = ed.HMC({z: qz}, data={x: x_train})\n",
        "inference_e.initialize()\n",
        "\n",
        "# M-step\n",
        "inference_m = ed.MAP(data={x: x_train, z: qz.params[inference_e.t]})\n",
        "optimizer = tf.train.AdamOptimizer(0.01, epsilon=1.0)\n",
        "\n",
        "inference_m.initialize(optimizer=optimizer)\n",
        "\n",
        "tf.global_variables_initializer().run()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dHFsbuH61rnX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# THIS IS EXAMPLE CODE FROM THE LINEAR_MIXED_MODELS NOTEBOOK\n",
        "# NOT TO BE INCLUDED IN THE FINAL FACTOR ANALYSIS NOTEBOOK\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# Set up E-step (MCMC).\n",
        "effect_students = tf.get_variable(  # `trainable=False` so unaffected by M-step\n",
        "    \"effect_students\", [num_students], trainable=False)\n",
        "effect_instructors = tf.get_variable(\n",
        "    \"effect_instructors\", [num_instructors], trainable=False)\n",
        "effect_departments = tf.get_variable(\n",
        "    \"effect_departments\", [num_departments], trainable=False)\n",
        "\n",
        "hmc = tfp.mcmc.HamiltonianMonteCarlo(\n",
        "    target_log_prob_fn=target_log_prob_fn,\n",
        "    step_size=0.015,\n",
        "    num_leapfrog_steps=3)\n",
        "\n",
        "current_state = [effect_students, effect_instructors, effect_departments]\n",
        "next_state, kernel_results = hmc.one_step(\n",
        "      current_state=current_state,\n",
        "      previous_kernel_results=hmc.bootstrap_results(current_state))\n",
        "\n",
        "expectation_update = tf.group(\n",
        "    effect_students.assign(next_state[0]),\n",
        "    effect_instructors.assign(next_state[1]),\n",
        "    effect_departments.assign(next_state[2]))\n",
        "\n",
        "# Set up M-step (gradient descent).\n",
        "# The following should work. However, TensorFlow raises an error about taking\n",
        "# gradients through IndexedSlices tensors. This may be a TF bug. For now,\n",
        "# we recompute the target's log probability at the current state.\n",
        "# loss = -kernel_results.accepted_results.target_log_prob\n",
        "with tf.control_dependencies([expectation_update]):\n",
        "  loss = -target_log_prob_fn(effect_students,\n",
        "                             effect_instructors,\n",
        "                             effect_departments)\n",
        "  optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
        "  minimization_update = optimizer.minimize(loss)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eMVaI2iWsYUf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess_1:\n",
        "  for _ in range(n_epoch - 1):\n",
        "      avg_loss = 0.0\n",
        "      for _ in range(FLAGS.n_iter_per_epoch):\n",
        "          info_dict_e = inference_e.update()\n",
        "          info_dict_m = inference_m.update()\n",
        "          avg_loss += info_dict_m['loss']\n",
        "          inference_e.print_progress(info_dict_e)\n",
        "\n",
        "      # Print a lower bound to the average marginal likelihood for an\n",
        "      # image.\n",
        "      avg_loss = avg_loss / n_iter_per_epoch\n",
        "      avg_loss = avg_loss / N\n",
        "      print(\"\\nlog p(x) >= {:0.3f}\".format(avg_loss))\n",
        "\n",
        "      # Prior predictive check.\n",
        "      images = x.eval()\n",
        "      for m in range(N):\n",
        "            imsave(os.path.join(out_dir, '%d.png') % m,\n",
        "                   images[m].reshape(28, 28))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "se6xvXxslxyP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Visualizing the graph we've constructed\n",
        "# draw_graph(linear_mixed_effects_model, features_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kTpcVhJKRp2f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "\n",
        "1. "
      ]
    },
    {
      "metadata": {
        "id": "Q86bku9CRp2g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.core.display import HTML\n",
        "def css_styling():\n",
        "    styles = open(\"../styles/custom.css\", \"r\").read()\n",
        "    return HTML(styles)\n",
        "css_styling()\n",
        "\n",
        "#  \"#F15854\",  // red\n",
        "#  \"#5DA5DA\",  // blue\n",
        "#  \"#FAA43A\",  // orange\n",
        "#  \"#60BD68\",  // green\n",
        "#  \"#F17CB0\",  // pink\n",
        "#  \"#B2912F\",  // brown\n",
        "#  \"#B276B2\",  // purple\n",
        "#  \"#DECF3F\",  // yellow\n",
        "#  \"#4D4D4D\",  // gray"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}