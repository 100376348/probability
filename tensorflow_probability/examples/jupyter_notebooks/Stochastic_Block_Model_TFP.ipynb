{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stochastic_Block_Model_TFP.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "1PeqMlDRWrSV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2018 The TensorFlow Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "metadata": {
        "id": "iXfx7eO4WrHc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\"); { display-mode: \"form\" }\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y7o7FF9yRqG2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Stochastic Block Model with TFP\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://drive.google.com/file/d/1N-Su0zIkLNFf-qPeCFipf1imrb2ErUgD/view?usp=sharing\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "\n",
        "Original content [this Repository](https://github.com/blei-lab/edward), created by [the Blei Lab](http://www.cs.columbia.edu/~blei/)\n",
        "\n",
        "Ported to Tensorflow Probability by Matthew McAteer ([`@MatthewMcAteer0`](https://twitter.com/MatthewMcAteer0)), with help from the TFP team at  Google ([`tfprobability@tensorflow.org`](mailto:tfprobability@tensorflow.org)).\n",
        "\n",
        "---\n",
        "\n",
        ">[Dependencies & Prerequisites](#scrollTo=2ZtWUjXYRXQi)\n",
        "\n",
        ">[Introduction](#scrollTo=2ZtWUjXYRXQi)\n",
        "\n",
        ">>[Data](#scrollTo=2ZtWUjXYRXQi)\n",
        "\n",
        ">>[Model](#scrollTo=2ZtWUjXYRXQi)\n",
        "\n",
        ">>[Inference](#scrollTo=2ZtWUjXYRXQi)\n",
        "\n",
        ">>[Criticism](#scrollTo=2ZtWUjXYRXQi)\n",
        "\n",
        ">[References](#scrollTo=2ZtWUjXYRXQi)\n"
      ]
    },
    {
      "metadata": {
        "id": "C20bDrJTbYMs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Dependencies & Prerequisites"
      ]
    },
    {
      "metadata": {
        "id": "7pSfVmKXVGHW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 install -q tfp-nightly\n",
        "!pip3 install -q observations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q9eVQSzYRqG5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "\n",
        "import time\n",
        "from observations.karate import karate\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Ellipse\n",
        "import seaborn as sns\n",
        "from IPython.core.pylabtools import figsize\n",
        "\n",
        "import tensorflow as tf                            # importing Tensorflow\n",
        "\n",
        "import tensorflow_probability as tfp               # Tensorflow probability\n",
        "from tensorflow_probability import edward2 as ed   # Edwardlib extension\n",
        "\n",
        "from sklearn.metrics.cluster import adjusted_rand_score\n",
        "\n",
        "tfd = tf.contrib.distributions             # Basic probability distribution toolkit\n",
        "tfb = tf.contrib.distributions.bijectors   # and their modifiers\n",
        "\n",
        "dtype = np.float32    # A tool to make sure we're inputing the right data type\n",
        "\n",
        "%matplotlib inline\n",
        "plt.style.use('fivethirtyeight')        # Styling plots like FiveThirtyEight\n",
        "\n",
        "%config InlineBackend.figure_format='retina' # improves resolution of plots\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')       # Some python imports raise depreciation warnings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tiMdViEJUQ7q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def session_options(enable_gpu_ram_resizing=True, enable_xla=True):\n",
        "    \"\"\"\n",
        "    Allowing the notebook to make use of GPUs if they're available.\n",
        "    \n",
        "    XLA (Accelerated Linear Algebra) is a domain-specific compiler for linear \n",
        "    algebra that optimizes TensorFlow computations.\n",
        "    \"\"\"\n",
        "    config = tf.ConfigProto()\n",
        "    config.log_device_placement = True\n",
        "    if enable_gpu_ram_resizing:\n",
        "        # `allow_growth=True` makes it possible to connect multiple colabs to your\n",
        "        # GPU. Otherwise the colab malloc's all GPU ram.\n",
        "        config.gpu_options.allow_growth = True\n",
        "    if enable_xla:\n",
        "        # Enable on XLA. https://www.tensorflow.org/performance/xla/.\n",
        "        config.graph_options.optimizer_options.global_jit_level = (\n",
        "            tf.OptimizerOptions.ON_1)\n",
        "    return config\n",
        "\n",
        "\n",
        "def reset_sess(config=None):\n",
        "    \"\"\"\n",
        "    Convenience function to create the TF graph & session or reset them.\n",
        "    \"\"\"\n",
        "    if config is None:\n",
        "        config = session_options()\n",
        "    global sess\n",
        "    tf.reset_default_graph()\n",
        "    try:\n",
        "        sess.close()\n",
        "    except:\n",
        "        pass\n",
        "    sess = tf.InteractiveSession(config=config)\n",
        "\n",
        "    \n",
        "def evaluate(tensors):\n",
        "    \"\"\"\n",
        "    A \"Universal\" evaluate function for both running either Graph mode (default)\n",
        "    or Eager mode (https://www.tensorflow.org/guide/eager) in Tensorflow.\n",
        "    \"\"\"\n",
        "    if context.executing_eagerly():\n",
        "        return (t.numpy() for t in tensprs)\n",
        "    with tf.get_default_session() as sess:\n",
        "        return sess.run(tensors)\n",
        "\n",
        "reset_sess()\n",
        "\n",
        "\n",
        "def strip_consts(graph_def, max_const_size=32):\n",
        "  \"\"\"\n",
        "  Strip large constant values from graph_def.\n",
        "  \"\"\"\n",
        "  strip_def = tf.GraphDef()\n",
        "  for n0 in graph_def.node:\n",
        "    n = strip_def.node.add()\n",
        "    n.MergeFrom(n0)\n",
        "    if n.op == 'Const':\n",
        "      tensor = n.attr['value'].tensor\n",
        "      size = len(tensor.tensor_content)\n",
        "      if size > max_const_size:\n",
        "        tensor.tensor_content = bytes(\"<stripped %d bytes>\"%size, 'utf-8')\n",
        "  return strip_def\n",
        "\n",
        "\n",
        "def draw_graph(model, *args, **kwargs):\n",
        "  \"\"\"\n",
        "  Visualize TensorFlow graph.\n",
        "  \"\"\"\n",
        "  graph = tf.Graph()\n",
        "  with graph.as_default():\n",
        "    model(*args, **kwargs)\n",
        "  graph_def = graph.as_graph_def()\n",
        "  strip_def = strip_consts(graph_def, max_const_size=32)\n",
        "  code = \"\"\"\n",
        "      <script>\n",
        "        function load() {{\n",
        "          document.getElementById(\"{id}\").pbtxt = {data};\n",
        "        }}\n",
        "      </script>\n",
        "      <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
        "      <div style=\"height:600px\">\n",
        "        <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
        "      </div>\n",
        "  \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
        "\n",
        "  iframe = \"\"\"\n",
        "      <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
        "  \"\"\".format(code.replace('\"', '&quot;'))\n",
        "  IPython.display.display(IPython.display.HTML(iframe))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QkCvgd12UFkH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Introduction"
      ]
    },
    {
      "metadata": {
        "id": "PhTEnVvmRqG-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data & parameters"
      ]
    },
    {
      "metadata": {
        "id": "F_4Ng4oB5Bw-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "  Load Zachary's Karate Club [@zachary1977information].\n",
        "  It is a social network of friendships between 34 members of a karate\n",
        "  club at a US university from 1970 to 1972. During the study a\n",
        "  conflict between instructor 'Mr. Hi' and administrator 'Officer' led\n",
        "  the club to split into two. Half of the members formed a new club\n",
        "  around 'Mr.  Hi'; other members found a new instructor or quit karate.\n",
        "  Args:\n",
        "    path: str.\n",
        "      Path to directory which either stores file or otherwise file will\n",
        "      be downloaded and extracted there. Filename is `out.ucidata-zachary`.\n",
        "  Returns:\n",
        "    Tuple of adjacency matrix as a np.darray `x_train` with 34 rows\n",
        "    and 34 columns and np.darray `y_train` of class memberships (0 for\n",
        "    'Mr.Hi' and 1 for 'Officer').\n",
        " \n",
        "\n",
        "[Observations](https://github.com/edwardlib/observations) provides\n",
        "a one line Python API for loading standard data sets in machine\n",
        "learning. It automates the process from downloading, extracting,\n",
        "loading, and preprocessing data. Observations helps keep the workflow\n",
        "reproducible and follow sensible standards.\n",
        "Observations is a standalone Python library and must be installed\n",
        "separate from Edward."
      ]
    },
    {
      "metadata": {
        "id": "EX4s78aE2h08",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_data, z = karate('~/data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mYu3-FJ_RqG_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_data, Z_true = karate(\"~/data\")\n",
        "N = X_data.shape[0]  # number of vertices\n",
        "K = 2  # number of clusters\n",
        "learning_rate = 1e-4\n",
        "max_steps = 10000\n",
        "epsilon= 0.001\n",
        "\n",
        "def compute_loss(latent_vars, data):\n",
        "    \"\"\" \n",
        "    Compute the loss associated with MAP calculations.\n",
        "    \"\"\"\n",
        "    dict_vals = {var: latent.value for var, latent in latent_vars.items()}\n",
        "    for x, datum in data.items(): # assuming we have the values as input\n",
        "        dict_vals[x] = datum\n",
        "\n",
        "    log_prob = 0.0\n",
        "    for z in latent_vars.keys():\n",
        "        z_copy = z.distribution.copy()\n",
        "        log_prob += tf.reduce_sum(z_copy.log_prob(dict_vals[z]))\n",
        "        \n",
        "    for x in data.keys():\n",
        "        x_copy = x.distribution.copy()\n",
        "        log_prob += tf.reduce_sum(x_copy.log_prob(dict_vals[x]))\n",
        "            \n",
        "    reg_penalty = tf.reduce_sum(tf.losses.get_regularization_losses())\n",
        "    loss = -log_prob + reg_penalty\n",
        "\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-wVVUlMIRqHF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model"
      ]
    },
    {
      "metadata": {
        "id": "b9bVaZoXRqHG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gamma = tfd.Dirichlet(tf.ones([K]))\n",
        "pi = tfd.Beta(tf.ones([K,K]), tf.ones([K,K]))\n",
        "z = tfd.Multinomial(tf.ones([V]), gamma)\n",
        "x = tfd.Bernoulli(tf.matmul(z, tf.matmul(pi, tf.transpose(z))))\n",
        "\n",
        "# gamma = ed.Dirichlet(tf.ones([K]))\n",
        "# pi = ed.Beta(tf.ones([K,K]), tf.ones([K,K]))\n",
        "# z = ed.Multinomial(tf.ones([V]), gamma)\n",
        "# x = ed.Bernoulli(tf.matmul(z, tf.matmul(pi, tf.transpose(z))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LiFbEKyMRqHJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define the MAP loss"
      ]
    },
    {
      "metadata": {
        "id": "Hfgg9WCLRqHK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "qgamma = tfd.VectorDeterministic(tf.nn.softmax(tf.get_variable('qgamma/params', [K]))) # Gamma must sum to one\n",
        "qpi = tfd.VectorDeterministic(tf.nn.sigmoid(tf.get_variable('qpi/params', [K, K]))) # Each pi must be between 0 and 1\n",
        "qz = tfd.VectorDeterministic(tf.nn.softmax(tf.get_variable('qz/params', [V,K]), axis=1)) # the Z_i must sum to one row-wise (axis 0)\n",
        "\n",
        "# qgamma = ed.VectorDeterministic(tf.nn.softmax(tf.get_variable('qgamma/params', [K]))) # Gamma must sum to one\n",
        "# qpi = ed.VectorDeterministic(tf.nn.sigmoid(tf.get_variable('qpi/params', [K, K]))) # Each pi must be between 0 and 1\n",
        "# qz = ed.VectorDeterministic(tf.nn.softmax(tf.get_variable('qz/params', [V,K]), axis=1)) # the Z_i must sum to one row-wise (axis 0)\n",
        "\n",
        "latent_vars = {gamma: qgamma, pi: qpi, z: qz}\n",
        "data = {x: x_data}\n",
        "MAP_loss = compute_loss(latent_vars, data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4CFb6Mr3RqHM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Inference"
      ]
    },
    {
      "metadata": {
        "id": "jGH6sfeGRqHN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.train.AdagradOptimizer(learning_rate)\n",
        "train_op = optimizer.minimize(MAP_loss)\n",
        "\n",
        "loss_vals = []\n",
        "with tf.Session() as session:\n",
        "    start = time.time()\n",
        "    session.run(tf.global_variables_initializer())\n",
        "     for step in range(max_steps):\n",
        "        _, loss_value = session.run([train_op, MAP_loss])\n",
        "        duration = time.time() - start\n",
        "        if step % 100 == 0:\n",
        "            print(\"Step: {:>3d} Loss: {:.3f} ({:.3f} sec)\".format(step, \n",
        "                                                                  loss_value,\n",
        "                                                                  duration))\n",
        "        if step > 0:\n",
        "            if abs(loss_vals[-1]-loss_value) <  epsilon:\n",
        "                break\n",
        "        loss_vals.append(loss_value)\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(range(len(loss_vals)), loss_vals)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bG1g4OMdlvuB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Visualizing the graph we've constructed\n",
        "# draw_graph(linear_mixed_effects_model, features_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b01hM5xjRqHR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "\n",
        "1. "
      ]
    },
    {
      "metadata": {
        "id": "sw0ybMH8RqHS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.core.display import HTML\n",
        "def css_styling():\n",
        "    styles = open(\"../styles/custom.css\", \"r\").read()\n",
        "    return HTML(styles)\n",
        "css_styling()\n",
        "\n",
        "#  \"#F15854\",  // red\n",
        "#  \"#5DA5DA\",  // blue\n",
        "#  \"#FAA43A\",  // orange\n",
        "#  \"#60BD68\",  // green\n",
        "#  \"#F17CB0\",  // pink\n",
        "#  \"#B2912F\",  // brown\n",
        "#  \"#B276B2\",  // purple\n",
        "#  \"#DECF3F\",  // yellow\n",
        "#  \"#4D4D4D\",  // gray\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}