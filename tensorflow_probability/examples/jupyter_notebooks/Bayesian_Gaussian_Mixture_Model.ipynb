{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JJ3UDciDVcB5"
      },
      "source": [
        "# Bayesian Gaussian Mixture Model and Hamiltonian MCMC\n",
        "\n",
        "In this colab we'll explore sampling from the posterior of a Bayesian Gaussian Mixture Model (BGMM) using only Tensorflow Probability primitives. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eZs1ShikNBK2"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7JjokKMbk2hJ"
      },
      "source": [
        "For $k\\in\\{1,\\ldots, K\\}$ mixture components each of dimension $D$, we'd like to model $i\\in\\{1,\\ldots,N\\}$ iid samples using the following Bayesian Gaussian Mixture Model:\n",
        "\n",
        "$$\\begin{align*}\n",
        "\\theta \u0026\\sim \\textsf{Dirichlet}(\\text{concentration}=\\alpha_0) \\\\\n",
        "\\mu_k \u0026\\sim \\textsf{Normal}(\\text{loc}=\\mu_{0k}, \\text{scale}=I_D) \\\\\n",
        "T_k \u0026\\sim \\textsf{Wishart}(\\text{df}=5, \\text{scale}=I_D) \\\\\n",
        "Z_i \u0026\\sim \\textsf{Categorical}(\\text{probs}=\\theta) \\\\\n",
        "Y_i \u0026\\sim \\textsf{Normal}(\\text{loc}=\\mu_{z_i}, \\text{scale}=T_{z_i}^{-1/2})\\\\\n",
        "\\end{align*}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iySRABi0qZnQ"
      },
      "source": [
        "Note, the `scale` arguments all have `cholesky` semantics. We use this convention because it is that of TF Distributions (which itself uses this convention in part because it is computationally advantageous). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y6X_Beihwzyi"
      },
      "source": [
        "Our goal is to generate samples from the posterior:\n",
        "\n",
        "$$p\\left(\\theta, \\{\\mu_k, T_k\\}_{k=1}^K \\Big| \\{y_i\\}_{i=1}^N, \\alpha_0, \\{\\mu_{ok}\\}_{k=1}^K\\right)$$\n",
        "\n",
        "Notice that $\\{Z_i\\}_{i=1}^N$ is not present--we're interested in only those random variables which don't scale with $N$.  (And luckily there's a TF distribution which handles marginalizing out $Z_i$.)\n",
        "\n",
        "It is not possible to directly sample from this distribution owing to a computationally intractable normalization term. \n",
        "\n",
        "[Metropolis-Hastings algorithms](https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm) are technique for for sampling from intractable-to-normalize distributions.\n",
        "\n",
        "Tensorflow Probability offers a number of MCMC options, including several based on Metropolis-Hastings. In this notebook, we'll use [Hamiltonian Monte Carlo](https://en.wikipedia.org/wiki/Hamiltonian_Monte_Carlo)  (`tfp.mcmc.HamiltonianMonteCarlo`). HMC is often a good choice because it can converge rapidly, samples the state space jointly (as opposed to coordinatewise), and leverages one of TF's virtues: automatic differentiation. That said, fitting a BGMM might actually be better served by other approaches, e.g., [Gibb's sampling](https://en.wikipedia.org/wiki/Gibbs_sampling)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "uswTWdgNu46j"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "import tensorflow_probability as tfp\n",
        "import tensorflow as tf \n",
        "\n",
        "from tensorflow.python.ops.distributions import util as distribution_util\n",
        "\n",
        "tfd = tfp.distributions\n",
        "tfb = tfp.distributions.bijectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "L9JaHPtQ3TOq"
      },
      "source": [
        "We're also going to try using [XLA](https://www.tensorflow.org/performance/xla/). In some cases this can result in a dramatic speed-up. However, if it doesn't work for you, feel free to change the `enable_xla=True` default to `False`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "ovNsKD-OEUzR"
      },
      "outputs": [],
      "source": [
        "def session_options(enable_gpu_ram_resizing=True, enable_xla=True):\n",
        "  \"\"\"Convenience function which sets common `tf.Session` options.\"\"\"\n",
        "  config = tf.ConfigProto()\n",
        "  config.log_device_placement = True\n",
        "  if enable_gpu_ram_resizing:\n",
        "    # `allow_growth=True` makes it possible to connect multiple colabs to your\n",
        "    # GPU. Otherwise the colab malloc's all GPU ram.\n",
        "    config.gpu_options.allow_growth = True\n",
        "  if enable_xla:\n",
        "    # Enable on XLA. https://www.tensorflow.org/performance/xla/.\n",
        "    config.graph_options.optimizer_options.global_jit_level = (\n",
        "        tf.OptimizerOptions.ON_1)\n",
        "  return config\n",
        "\n",
        "def reset_sess(config=None):\n",
        "  \"\"\"Convenience function to create the TF graph and session, or reset them.\"\"\"\n",
        "  if config is None:\n",
        "    config = session_options()\n",
        "  tf.reset_default_graph()\n",
        "  global sess\n",
        "  try:\n",
        "    sess.close()\n",
        "  except:\n",
        "    pass\n",
        "  sess = tf.InteractiveSession(config=config)\n",
        "\n",
        "reset_sess()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TVpiT3LLyfcO"
      },
      "source": [
        "### Unconstrained Representation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JS8XOsxiyiBV"
      },
      "source": [
        "Hamiltonian Monte Carlo (HMC) requires the target log-probability function be differentiable with respect to its arguments.  Furthermore, HMC can exhibit dramatically higher statistical efficiency if the state-space is unconstrained.\n",
        "\n",
        "This means we'll have to work out two main issues when sampling from the BGMM posterior:\n",
        "\n",
        "1. $\\theta$ represents a discrete probability vector, i.e., must be such that $\\sum_{k=1}^K \\theta_k = 1$ and $\\theta_k\u003e0$.\n",
        "2. $T_k$ represents an inverse covariance matrix, i.e., must be such that $T_k \\succ 0$, i.e., is [positive definite](https://en.wikipedia.org/wiki/Positive-definite_matrix).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Vt9SXJzO0Cks"
      },
      "source": [
        "Our plan is:\n",
        "\n",
        "1. transform the constrained variables to an unconstrained space\n",
        "2. run the MCMC in unconstrained space\n",
        "3. transform the unconstrained variables back to the constrained space.\n",
        "\n",
        "We'll use [`Bijector`s](https://www.tensorflow.org/api_docs/python/tf/distributions/bijectors/Bijector) to transform random variables to unconstrained space; the following code block implements the necessary  transformations.\n",
        "\n",
        "- The [`Dirichlet`](https://en.wikipedia.org/wiki/Dirichlet_distribution) is transformed to unconstrained space via the inverted [softmax function](https://en.wikipedia.org/wiki/Softmax_function).\n",
        "\n",
        "- We'll parameterize the [multivariate Normal](https://en.wikipedia.org/wiki/Multivariate_normal_distribution) by its [precision matrix](https://en.wikipedia.org/wiki/Precision_(statistics%29) rather than covariance matrix. By using the transform `tfb.Invert(tfb.Affine(...))`,  the `log_prob` calculation uses [`tf.matmul`](https://www.tensorflow.org/api_docs/python/tf/matmul) instead of [`tf.linalg.triangular_solve`](https://www.tensorflow.org/api_docs/python/tf/matrix_triangular_solve) (as would be the case for `tfd.MultivariateNormalTriL`). Using `tf.matmul` is advantageous since it is usually faster owing to better cache locality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "Zv_GfWWkvNfi"
      },
      "outputs": [],
      "source": [
        "class UnconstrainedDirichlet(tfd.TransformedDistribution):\n",
        "  \"\"\"Distribution over SoftmaxInverse(Dirichlet).\"\"\"\n",
        "\n",
        "  def __init__(self, concentration, name=None):\n",
        "    super(UnconstrainedDirichlet, self).__init__(\n",
        "        distribution=tfd.Dirichlet(concentration),\n",
        "        bijector=tfb.Invert(tfb.SoftmaxCentered()),\n",
        "        name=name)\n",
        "\n",
        "class MVNInverseTriL(tfd.TransformedDistribution):\n",
        "  \"\"\"MVN from loc and (Cholesky) precision matrix.\"\"\"\n",
        "\n",
        "  def __init__(self, loc, precision_tril, name=None):\n",
        "    super(MVNInverseTriL, self).__init__(\n",
        "        distribution=tfd.Independent(tfd.Normal(loc, scale=tf.ones_like(loc)),\n",
        "                                     reinterpreted_batch_ndims=1),\n",
        "        bijector=tfb.Invert(tfb.Affine(scale_tril=precision_tril)),\n",
        "        name=name)\n",
        "\n",
        "def make_tril(x, transform_fn=tf.abs):\n",
        "  \"\"\"Swaps `diag_part(x)` with `f(diag_part(x))`.\"\"\"\n",
        "  y = tfd.fill_triangular(x)\n",
        "  if transform_fn is None:\n",
        "    return y\n",
        "  new_diag = transform_fn(tf.matrix_diag_part(y))\n",
        "  return tf.linalg.set_diag(y, new_diag)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JDOkWhDQg4ZG"
      },
      "source": [
        "The `tfd.Independent` distribution turns independent draws of one distribution, into a multivariate distribution with statistically independent coordinates. In terms of computing `log_prob`, this \"meta-distribution\" manifests as a simple sum over the event dimension(s)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N60z8scN1v6E"
      },
      "source": [
        "Using the above `TransformedDistribution`s, specifying our priors as unconstrained random variables is easy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "xhzxySDjL2-S"
      },
      "outputs": [],
      "source": [
        "dtype = np.float32\n",
        "dims = 2\n",
        "components = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "xAOmHhZ7LzDQ"
      },
      "outputs": [],
      "source": [
        "rv_logits = UnconstrainedDirichlet(concentration=np.ones(components, dtype) / 10.)\n",
        "\n",
        "rv_loc = tfd.Independent(\n",
        "    tfd.Normal(\n",
        "        loc=np.stack([\n",
        "            -np.ones(dims, dtype),\n",
        "            np.zeros(dims, dtype),\n",
        "            np.ones(dims, dtype),\n",
        "        ]),\n",
        "        scale=tf.ones([components, dims], dtype)),\n",
        "    reinterpreted_batch_ndims=1)\n",
        "\n",
        "rv_precision = tfd.WishartCholesky(\n",
        "    df=5,\n",
        "    scale=np.stack([np.eye(dims, dtype=dtype)]*components),\n",
        "    cholesky_input_output_matrices=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "height": 68
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 53,
          "status": "ok",
          "timestamp": 1527914772224,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "KSTp8aAIAv0O",
        "outputId": "42c866a8-70eb-4e52-82d4-b308fbd44e96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.distributions.UnconstrainedDirichlet(\"invert_softmax_centeredDirichlet/\", batch_shape=(), event_shape=(2,), dtype=float32)\n",
            "tf.distributions.Independent(\"IndependentNormal/\", batch_shape=(3,), event_shape=(2,), dtype=float32)\n",
            "tf.distributions.WishartCholesky(\"WishartCholesky/\", batch_shape=(3,), event_shape=(2, 2), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "print(rv_logits)\n",
        "print(rv_loc)\n",
        "print(rv_precision)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8ZOG0OR815Nr"
      },
      "source": [
        "By using `tfd.MixtureSameFamily`, we're able to automatically integrate out the categorical $\\{Z_i\\}_{i=1}^N$ draws."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "CpLnRJr2TXYD"
      },
      "outputs": [],
      "source": [
        "def joint_log_prob(observations, logits, loc, flat_chol_precision):\n",
        "  \"\"\"BGMM with priors: loc=Normal, precision=Inverse-Wishart, mix=Dirichlet.\n",
        "\n",
        "  Our formulation differs from the specified Dirichlet governed mixture over\n",
        "  Normal-Normal-InverseWishart distribution. We represent the random variables\n",
        "  in an unconstrained space by applying differentiable, bijective\n",
        "  transformations. Since this representation is bijective, we can easily recover\n",
        "  the original formulation.\n",
        "\n",
        "  Args:\n",
        "    observations: `[n, d]`-shaped `Tensor` representing Bayesian Gaussian\n",
        "      Mixture model draws. Each sample is a length-`d` vector.\n",
        "    logits: `[K]`-shaped `Tensor` representing random draw from\n",
        "      `SoftmaxInverse(Dirichlet)` prior.\n",
        "    flat_loc_chol_precision: `[K, d * (d + 1) // 2]`-shaped `Tensor`\n",
        "      representing `K` triangular `cholesky(Precision)` matrices, each being a\n",
        "      flattened draw from a Wishart distribution.\n",
        "\n",
        "  Returns:\n",
        "    log_prob: `Tensor` representing joint log-density over all inputs.\n",
        "  \"\"\"\n",
        "  chol_precision = make_tril(flat_chol_precision)\n",
        "  rv_observations = tfd.MixtureSameFamily(\n",
        "      mixture_distribution=tfd.Categorical(\n",
        "          # Stay in logits-space by exploiting the fact that SoftmaxCentered\n",
        "          # appends to back.\n",
        "          logits=distribution_util.pad(logits, axis=-1, back=True)),\n",
        "      components_distribution=MVNInverseTriL(\n",
        "          loc=loc,\n",
        "          precision_tril=chol_precision))\n",
        "  log_prob_parts = [\n",
        "      rv_observations.log_prob(observations), # Sum over samples.\n",
        "      rv_logits.log_prob(logits)[..., tf.newaxis], \n",
        "      rv_loc.log_prob(loc),                   # Sum over components.\n",
        "      rv_precision.log_prob(chol_precision),  # Sum over components.\n",
        "  ]\n",
        "  sum_log_prob = tf.reduce_sum(tf.concat(log_prob_parts, axis=-1), axis=-1)\n",
        "  # Note: for easy debugging, uncomment the following:\n",
        "  # sum_log_prob = tf.Print(sum_log_prob, log_prob_parts)\n",
        "  return sum_log_prob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7jTMXdymV1QJ"
      },
      "source": [
        "## Generate \"Training\" Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rl4brz3G3pS7"
      },
      "source": [
        "For this demo, we'll sample some random data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "1AJZAtwXV8RQ"
      },
      "outputs": [],
      "source": [
        "num_samples = 1000\n",
        "true_loc = np.array([[-2, -2],\n",
        "                     [0, 0],\n",
        "                     [2, 2]], dtype)\n",
        "random = np.random.RandomState(seed=42)\n",
        "\n",
        "true_hidden_component = random.randint(0, components, num_samples)\n",
        "observations = (true_loc[true_hidden_component] +\n",
        "                random.randn(num_samples, dims).astype(dtype))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zVOvMh7MV37A"
      },
      "source": [
        "## Bayesian Inference using HMC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cdN3iKFT32Jp"
      },
      "source": [
        "Now that we've used TFD to specify our model in unconstrained state space (and obtained some oberved data), we have all the necessary pieces to run HMC.\n",
        "\n",
        "To do this, we'll use a [closure](https://en.wikipedia.org/wiki/Closure_(computer_programming%29#Anonymous_functions) to \"pin down\" the things we don't want to sample. In this case that means we need only pin down `observations`. (The hyper-parameters are already baked in to the prior distributions and not part of the `joint_log_prob` function signature.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "a0OMIWIYeMmQ"
      },
      "outputs": [],
      "source": [
        "unnormalized_posterior_log_prob = lambda *args: joint_log_prob(observations, *args)\n",
        "\n",
        "initial_state = [\n",
        "    tf.fill([components-1], value=np.array(0, dtype), name='logits'),\n",
        "    tf.constant(np.array([[-2, -2],\n",
        "                          [0, 0],\n",
        "                          [2, 2]], dtype), name='loc'),\n",
        "    distribution_util.fill_triangular_inverse(\n",
        "        tf.eye(dims, batch_shape=[components], dtype=dtype),\n",
        "        name='flat_chol_precision'),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "0zq6QJJ-NSPJ"
      },
      "outputs": [],
      "source": [
        "[logits, loc, flat_chol_precision], kernel_results = tfp.mcmc.sample_chain(\n",
        "    num_results=2000,\n",
        "    num_burnin_steps=500,\n",
        "    kernel=tfp.mcmc.HamiltonianMonteCarlo(\n",
        "        target_log_prob_fn=unnormalized_posterior_log_prob,\n",
        "        step_size=0.0249,\n",
        "        num_leapfrog_steps=5),\n",
        "    current_state=initial_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "_ceX1A3-ZFiN"
      },
      "outputs": [],
      "source": [
        "probs = tfb.SoftmaxCentered().forward(logits)\n",
        "chol_precision = make_tril(flat_chol_precision)\n",
        "\n",
        "acceptance_rate = tf.reduce_mean(tf.to_float(kernel_results.is_accepted))\n",
        "mean_logits = tf.reduce_mean(logits, axis=0)\n",
        "mean_probs = tf.reduce_mean(probs, axis=0)\n",
        "mean_loc = tf.reduce_mean(loc, axis=0)\n",
        "mean_chol_precision = tf.reduce_mean(chol_precision, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kmpTFZcVmByb"
      },
      "source": [
        "Note: we've already tuned the `step_size` and `num_leapfrog_steps` to approximately achieve an [asymptotically optimal rate of 0.651](https://arxiv.org/abs/1001.4460)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QLEz96mg6fpZ"
      },
      "source": [
        "We'll now execute the chain and print the posterior means."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "3B2yJWVmNcrm"
      },
      "outputs": [],
      "source": [
        "[\n",
        "    acceptance_rate_,\n",
        "    mean_logits_,\n",
        "    mean_probs_,\n",
        "    mean_loc_,\n",
        "    mean_chol_precision_,\n",
        "    probs_,\n",
        "    loc_,\n",
        "    chol_precision_,\n",
        "] = sess.run([\n",
        "    acceptance_rate,\n",
        "    mean_logits,\n",
        "    mean_probs,\n",
        "    mean_loc,\n",
        "    mean_chol_precision,\n",
        "    probs,\n",
        "    loc,\n",
        "    chol_precision,\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "height": 325
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 64,
          "status": "ok",
          "timestamp": 1527914788332,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "bqJ6RSJxegC6",
        "outputId": "666117e9-d098-47dd-8b4d-8893bb1f08f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    acceptance_rate: 0.6435\n",
            "         avg logits: [ 0.09875359 -0.42216286]\n",
            "          avg probs: [ 0.39828101  0.24060518  0.36111385]\n",
            "\n",
            "            avg loc:\n",
            " [[-1.85704136 -1.57462239]\n",
            " [-0.00555692  0.03425808]\n",
            " [ 1.85838342  1.63165784]]\n",
            "\n",
            "avg chol(precision):\n",
            " [[[ 0.99537122  0.        ]\n",
            "  [-0.07899799  0.96627843]]\n",
            "\n",
            " [[ 1.22457707  0.        ]\n",
            "  [ 0.31024155  1.09806609]]\n",
            "\n",
            " [[ 0.96028364  0.        ]\n",
            "  [-0.1234903   0.9684577 ]]]\n"
          ]
        }
      ],
      "source": [
        "print('    acceptance_rate:', acceptance_rate_)\n",
        "print('         avg logits:', mean_logits_)\n",
        "print('          avg probs:', mean_probs_)\n",
        "print('\\n            avg loc:\\n', mean_loc_)\n",
        "print('\\navg chol(precision):\\n', mean_chol_precision_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "height": 287
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 4915,
          "status": "ok",
          "timestamp": 1527914793305,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "zFOU0j9kPdUy",
        "outputId": "3a8ac196-29cf-4e81-c09d-fe94aed445dd"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEOCAYAAACUxJyzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "\u003cmatplotlib.figure.Figure at 0x7fae18d13bd0\u003e"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "ax = sns.kdeplot(loc_[:,0,0], loc_[:,0,1], shade=True)\n",
        "ax = sns.kdeplot(loc_[:,1,0], loc_[:,1,1], shade=True)\n",
        "ax = sns.kdeplot(loc_[:,2,0], loc_[:,2,1], shade=True)\n",
        "plt.title('KDE of loc draws');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NmfNIM1c6mwc"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t8LeIeMn6ot4"
      },
      "source": [
        "This simple colab demonstrated how Tensorflow Probability primitives can be used to build hierarchical Bayesian mixture models."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "default_view": {},
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      },
      "name": "Bayesian_Gaussian_Mixture_Model.ipynb",
      "provenance": [
        {
          "file_id": "1rxhvVh5S5WeWnyEBHqTiH_z0oGZVSGyx",
          "timestamp": 1527714835004
        }
      ],
      "version": "0.3.2",
      "views": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
