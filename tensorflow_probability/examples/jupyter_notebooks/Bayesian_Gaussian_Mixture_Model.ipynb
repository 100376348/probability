{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JJ3UDciDVcB5"
      },
      "source": [
        "# Bayesian Gaussian Mixture Model and Hamiltonian MCMC\n",
        "\n",
        "In this colab we'll explore sampling from the posterior of a Bayesian Gaussian Mixture Model (BGMM) using only Tensorflow Probability primitives."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eZs1ShikNBK2"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7JjokKMbk2hJ"
      },
      "source": [
        "For $k\\in\\{1,\\ldots, K\\}$ mixture components each of dimension $D$, we'd like to model $i\\in\\{1,\\ldots,N\\}$ iid samples using the following Bayesian Gaussian Mixture Model:\n",
        "\n",
        "$$\\begin{align*}\n",
        "\\theta \u0026\\sim \\text{Dirichlet}(\\text{concentration}=\\alpha_0)\\\\\n",
        "\\mu_k \u0026\\sim \\text{Normal}(\\text{loc}=\\mu_{0k}, \\text{scale}=I_D)\\\\\n",
        "T_k \u0026\\sim \\text{Wishart}(\\text{df}=5, \\text{scale}=I_D)\\\\\n",
        "Z_i \u0026\\sim \\text{Categorical}(\\text{probs}=\\theta)\\\\\n",
        "Y_i \u0026\\sim \\text{Normal}(\\text{loc}=\\mu_{z_i}, \\text{scale}=T_{z_i}^{-1/2})\\\\\n",
        "\\end{align*}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iySRABi0qZnQ"
      },
      "source": [
        "Note, the `scale` arguments all have `cholesky` semantics. We use this convention because it is that of TF Distributions (which itself uses this convention in part because it is computationally advantageous)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y6X_Beihwzyi"
      },
      "source": [
        "Our goal is to generate samples from the posterior:\n",
        "\n",
        "$$p\\left(\\theta, \\{\\mu_k, T_k\\}_{k=1}^K \\Big| \\{y_i\\}_{i=1}^N, \\alpha_0, \\{\\mu_{ok}\\}_{k=1}^K\\right)$$\n",
        "\n",
        "Notice that $\\{Z_i\\}_{i=1}^N$ is not present--we're interested in only those random variables which don't scale with $N$.  (And luckily there's a TF distribution which handles marginalizing out $Z_i$.)\n",
        "\n",
        "It is not possible to directly sample from this distribution owing to a computationally intractable normalization term.\n",
        "\n",
        "[Metropolis-Hastings algorithms](https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm) are technique for for sampling from intractable-to-normalize distributions.\n",
        "\n",
        "Tensorflow Probability offers a number of MCMC options, including several based on Metropolis-Hastings. In this notebook, we'll use [Hamiltonian Monte Carlo](https://en.wikipedia.org/wiki/Hamiltonian_Monte_Carlo)  (`tfp.mcmc.HamiltonianMonteCarlo`). HMC is often a good choice because it can converge rapidly, samples the state space jointly (as opposed to coordinatewise), and leverages one of TF's virtues: automatic differentiation. That said, sampling from a BGMM posterior might actually be better done by other approaches, e.g., [Gibb's sampling](https://en.wikipedia.org/wiki/Gibbs_sampling)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "uswTWdgNu46j"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import matplotlib.pyplot as plt; plt.style.use('ggplot')\n",
        "import numpy as np\n",
        "import seaborn as sns; sns.set_context('notebook')\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "from tensorflow.python.ops.distributions import util as distribution_util\n",
        "\n",
        "tfd = tfp.distributions\n",
        "tfb = tfp.bijectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "ovNsKD-OEUzR"
      },
      "outputs": [],
      "source": [
        "def session_options(enable_gpu_ram_resizing=True):\n",
        "  \"\"\"Convenience function which sets common `tf.Session` options.\"\"\"\n",
        "  config = tf.ConfigProto()\n",
        "  config.log_device_placement = True\n",
        "  if enable_gpu_ram_resizing:\n",
        "    # `allow_growth=True` makes it possible to connect multiple colabs to your\n",
        "    # GPU. Otherwise the colab malloc's all GPU ram.\n",
        "    config.gpu_options.allow_growth = True\n",
        "  return config\n",
        "\n",
        "def reset_sess(config=None):\n",
        "  \"\"\"Convenience function to create the TF graph and session, or reset them.\"\"\"\n",
        "  if config is None:\n",
        "    config = session_options()\n",
        "  tf.reset_default_graph()\n",
        "  global sess\n",
        "  try:\n",
        "    sess.close()\n",
        "  except:\n",
        "    pass\n",
        "  sess = tf.InteractiveSession(config=config)\n",
        "\n",
        "reset_sess()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Uj9uHZN2yUqz"
      },
      "source": [
        "Before actually building the model, we'll need to define a new type of distribution.  From the model specification above, its clear we're parameterizing the MVN with an inverse covariance matrix, i.e.,  [precision matrix](https://en.wikipedia.org/wiki/Precision_(statistics%29).  To accomplish this in TF,  we'll need to roll out our `Bijector`.  This `Bijector` will use the forward transformation:\n",
        "\n",
        "- `Y =`  [`tf.matrix_triangular_solve`](https://www.tensorflow.org/api_docs/python/tf/matrix_triangular_solve)`(tf.matrix_transpose(chol_precision_tril), X, lower=False) + loc`. \n",
        "\n",
        "And the `log_prob` calculation is just the inverse, i.e.:\n",
        "\n",
        "- `X =` [`tf.matmul`](https://www.tensorflow.org/api_docs/python/tf/matmul)`(chol_precision_tril, X - loc, adjoint_a=True)`.\n",
        "\n",
        "Since all we need for HMC is `log_prob`, this means we avoid ever calling `tf.matrix_triangular_solve` (as would be the case for `tfd.MultivariateNormalTriL`). This is advantageous since `tf.matmul` is usually faster owing to better cache locality.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "Zv_GfWWkvNfi"
      },
      "outputs": [],
      "source": [
        "from tensorflow_probability.python.bijectors.shape import _DistributionShape\n",
        "\n",
        "class AffinePrecision(tfb.Bijector):\n",
        "  \"\"\"Affine (inverse) transformation: `Y = chol_precision_tril.T \\ X + loc`.\"\"\"\n",
        "  def __init__(self,\n",
        "               chol_precision_tril,\n",
        "               shift=None,\n",
        "               validate_args=False,\n",
        "               name='inverse_affine_tril'):\n",
        "    with tf.name_scope(name, values=[shift, chol_precision_tril]) as name:\n",
        "      self._shift = tf.convert_to_tensor(shift, name='shift')\n",
        "      self._chol_precision_tril = tf.convert_to_tensor(\n",
        "          chol_precision_tril, name='chol_precision_tril')\n",
        "      self._shaper = _DistributionShape(\n",
        "            batch_ndims=(tf.rank(self._chol_precision_tril)\n",
        "                         if self._chol_precision_tril.shape.ndims is None\n",
        "                         else self._chol_precision_tril.shape.ndims) - 2,\n",
        "            event_ndims=1,\n",
        "            validate_args=validate_args)\n",
        "      super(AffinePrecision, self).__init__(\n",
        "        forward_min_event_ndims=1,\n",
        "        graph_parents=(\n",
        "            [self._shift] if self._shift is not None else [] +\n",
        "            self._chol_precision_tril),\n",
        "        is_constant_jacobian=True,\n",
        "        dtype=self._chol_precision_tril.dtype.base_dtype,\n",
        "        validate_args=validate_args,\n",
        "        name=name)\n",
        "\n",
        "  @property\n",
        "  def shift(self):\n",
        "    \"\"\"The `shift` in `Y = inv_scale.T \\ X + shift`.\"\"\"\n",
        "    return self._shift\n",
        "\n",
        "  @property\n",
        "  def chol_precision_tril(self):\n",
        "    \"\"\"The `chol_precision_tril` in `Y = chol_precision_tril.T \\ X + shift`.\"\"\"\n",
        "    return self._chol_precision_tril\n",
        "\n",
        "  def _forward(self, x):\n",
        "    y = x\n",
        "    y, sample_shape = self._shaper.make_batch_of_event_sample_matrices(\n",
        "        y, expand_batch_dim=False)\n",
        "    # Solve fails if the op is singular so we may safely skip this assertion.\n",
        "    y = tf.matrix_triangular_solve(\n",
        "        tf.matrix_transpose(self.chol_precision_tril), y, lower=False)\n",
        "    y = self._shaper.undo_make_batch_of_event_sample_matrices(\n",
        "        y, sample_shape, expand_batch_dim=False)\n",
        "    if self.shift is not None:\n",
        "      y += self.shift\n",
        "    return y\n",
        "\n",
        "  def _inverse(self, y):\n",
        "    x = y\n",
        "    if self.shift is not None:\n",
        "      x -= self.shift\n",
        "    x, sample_shape = self._shaper.make_batch_of_event_sample_matrices(\n",
        "        x, expand_batch_dim=False)\n",
        "    x = tf.matmul(self.chol_precision_tril, x, adjoint_a=True)\n",
        "    x = self._shaper.undo_make_batch_of_event_sample_matrices(\n",
        "        x, sample_shape, expand_batch_dim=False)\n",
        "    return x\n",
        "\n",
        "  def _inverse_log_det_jacobian(self, x):\n",
        "    diag = tf.matrix_diag_part(self.chol_precision_tril)\n",
        "    return tf.reduce_sum(tf.log(tf.abs(diag)), axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "nc4yy6vW-lC_"
      },
      "outputs": [],
      "source": [
        "class MVNCholPrecisionTriL(tfd.TransformedDistribution):\n",
        "  \"\"\"MVN from loc and (Cholesky) precision matrix.\"\"\"\n",
        "\n",
        "  def __init__(self, loc, chol_precision_tril, name=None):\n",
        "    super(MVNCholPrecisionTriL, self).__init__(\n",
        "        distribution=tfd.Independent(tfd.Normal(tf.zeros_like(loc),\n",
        "                                                scale=tf.ones_like(loc)),\n",
        "                                     reinterpreted_batch_ndims=1),\n",
        "        bijector=AffinePrecision(shift=loc,\n",
        "                                 chol_precision_tril=chol_precision_tril),\n",
        "        name=name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JDOkWhDQg4ZG"
      },
      "source": [
        "The `tfd.Independent` distribution turns independent draws of one distribution, into a multivariate distribution with statistically independent coordinates. In terms of computing `log_prob`, this \"meta-distribution\" manifests as a simple sum over the event dimension(s)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Pfkc8cmhh2Qz"
      },
      "source": [
        "Since this distribution is kind of tricky, let's quickly verify that our `MVNCholPrecisionTriL` works as we think it should."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "height": 165
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 207,
          "status": "ok",
          "timestamp": 1529883641078,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "GhqbjwlIh1Vn",
        "outputId": "765b9a88-1b30-47e9-8fca-63906567702a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "true mean: [ 1. -1.]\n",
            "sample mean: [ 1.00026524 -1.00012064]\n",
            "true cov:\n",
            " [[ 1.0625   -0.03125 ]\n",
            " [-0.03125   0.015625]]\n",
            "sample cov:\n",
            " [[ 1.06412709 -0.03126179]\n",
            " [-0.03126179  0.0155931 ]]\n"
          ]
        }
      ],
      "source": [
        "def compute_sample_stats(d, seed=42, n=int(1e6)):\n",
        "  x = d.sample(n, seed=seed)\n",
        "  sample_mean = tf.reduce_mean(x, axis=0, keepdims=True)\n",
        "  s = x - sample_mean\n",
        "  sample_cov = tf.matmul(s, s, adjoint_a=True) / tf.cast(n, s.dtype)\n",
        "  sample_scale = tf.cholesky(sample_cov)\n",
        "  sample_mean = sample_mean[0]\n",
        "  return [\n",
        "      sample_mean,\n",
        "      sample_cov,\n",
        "      sample_scale,\n",
        "  ]\n",
        "\n",
        "dtype = np.float32\n",
        "true_loc = np.array([1., -1.], dtype=dtype)\n",
        "true_chol_precision = np.array([[1., 0.],\n",
        "                                [2., 8.]],\n",
        "                               dtype=dtype)\n",
        "true_precision = np.matmul(true_chol_precision, true_chol_precision.T)\n",
        "true_cov = np.linalg.inv(true_precision)\n",
        "\n",
        "d = MVNCholPrecisionTriL(\n",
        "    loc=true_loc,\n",
        "    chol_precision_tril=true_chol_precision)\n",
        "\n",
        "[\n",
        "    sample_mean_,\n",
        "    sample_cov_,\n",
        "    sample_scale_,\n",
        "] = sess.run(compute_sample_stats(d))\n",
        "\n",
        "print('true mean:', true_loc)\n",
        "print('sample mean:', sample_mean_)\n",
        "print('true cov:\\n', true_cov)\n",
        "print('sample cov:\\n', sample_cov_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N60z8scN1v6E"
      },
      "source": [
        "Since the sample mean and covariance are close to the true mean and covariance, it seems like the distribution is correctly implemented. Now, we'll use `MVNCholPrecisionTriL` and  stock`tfp.distributions` to specify the BGMM prior random variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "xhzxySDjL2-S"
      },
      "outputs": [],
      "source": [
        "dtype = np.float32\n",
        "dims = 2\n",
        "components = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "xAOmHhZ7LzDQ"
      },
      "outputs": [],
      "source": [
        "rv_mix_probs = tfd.Dirichlet(\n",
        "    concentration=np.ones(components, dtype) / 10.,\n",
        "    name='rv_mix_probs')\n",
        "\n",
        "rv_loc = tfd.Independent(\n",
        "    tfd.Normal(\n",
        "        loc=np.stack([\n",
        "            -np.ones(dims, dtype),\n",
        "            np.zeros(dims, dtype),\n",
        "            np.ones(dims, dtype),\n",
        "        ]),\n",
        "        scale=tf.ones([components, dims], dtype)),\n",
        "    reinterpreted_batch_ndims=1,\n",
        "    name='rv_loc')\n",
        "\n",
        "rv_precision = tfd.WishartCholesky(\n",
        "    df=5,\n",
        "    scale=np.stack([np.eye(dims, dtype=dtype)]*components),\n",
        "    cholesky_input_output_matrices=True,\n",
        "    name='rv_precision')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "height": 72
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 39,
          "status": "ok",
          "timestamp": 1529883641533,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "KSTp8aAIAv0O",
        "outputId": "78f7aef8-ae87-4fc0-ecce-4a0295dbb51d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.distributions.Dirichlet(\"rv_mix_probs/\", batch_shape=(), event_shape=(3,), dtype=float32)\n",
            "tf.distributions.Independent(\"rv_loc/\", batch_shape=(3,), event_shape=(2,), dtype=float32)\n",
            "tf.distributions.WishartCholesky(\"rv_precision/\", batch_shape=(3,), event_shape=(2, 2), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "print(rv_mix_probs)\n",
        "print(rv_loc)\n",
        "print(rv_precision)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8ZOG0OR815Nr"
      },
      "source": [
        "Using the three random variables defined above, we can now specify the joint log probability function. To do this we'll use `tfd.MixtureSameFamily` to automatically integrate out the categorical $\\{Z_i\\}_{i=1}^N$ draws."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "CpLnRJr2TXYD"
      },
      "outputs": [],
      "source": [
        "def joint_log_prob(observations, mix_probs, loc, chol_precision):\n",
        "  \"\"\"BGMM with priors: loc=Normal, precision=Inverse-Wishart, mix=Dirichlet.\n",
        "\n",
        "  Args:\n",
        "    observations: `[n, d]`-shaped `Tensor` representing Bayesian Gaussian\n",
        "      Mixture model draws. Each sample is a length-`d` vector.\n",
        "    mix_probs: `[K]`-shaped `Tensor` representing random draw from\n",
        "      `SoftmaxInverse(Dirichlet)` prior.\n",
        "    loc: `[K, d]`-shaped `Tensor` representing the location parameter of the\n",
        "      `K` components.\n",
        "    chol_precision: `[K, d, d]`-shaped `Tensor` representing `K` lower\n",
        "      triangular `cholesky(Precision)` matrices, each being sampled from\n",
        "      a Wishart distribution.\n",
        "\n",
        "  Returns:\n",
        "    log_prob: `Tensor` representing joint log-density over all inputs.\n",
        "  \"\"\"\n",
        "  rv_observations = tfd.MixtureSameFamily(\n",
        "      mixture_distribution=tfd.Categorical(probs=mix_probs),\n",
        "      components_distribution=MVNCholPrecisionTriL(\n",
        "          loc=loc,\n",
        "          chol_precision_tril=chol_precision))\n",
        "  log_prob_parts = [\n",
        "      rv_observations.log_prob(observations), # Sum over samples.\n",
        "      rv_mix_probs.log_prob(mix_probs)[..., tf.newaxis],\n",
        "      rv_loc.log_prob(loc),                   # Sum over components.\n",
        "      rv_precision.log_prob(chol_precision),  # Sum over components.\n",
        "  ]\n",
        "  sum_log_prob = tf.reduce_sum(tf.concat(log_prob_parts, axis=-1), axis=-1)\n",
        "  # Note: for easy debugging, uncomment the following:\n",
        "  # sum_log_prob = tf.Print(sum_log_prob, log_prob_parts)\n",
        "  return sum_log_prob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QM1idLJazkGC"
      },
      "source": [
        "Notice that this function internally defines a new random variable. This is necessary since the `observations` RV depends on samples from the RVs defined further above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7jTMXdymV1QJ"
      },
      "source": [
        "## Generate \"Training\" Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rl4brz3G3pS7"
      },
      "source": [
        "For this demo, we'll sample some random data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "1AJZAtwXV8RQ"
      },
      "outputs": [],
      "source": [
        "num_samples = 1000\n",
        "true_loc = np.array([[-2, -2],\n",
        "                     [0, 0],\n",
        "                     [2, 2]], dtype)\n",
        "random = np.random.RandomState(seed=42)\n",
        "\n",
        "true_hidden_component = random.randint(0, components, num_samples)\n",
        "observations = (true_loc[true_hidden_component] +\n",
        "                random.randn(num_samples, dims).astype(dtype))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zVOvMh7MV37A"
      },
      "source": [
        "## Bayesian Inference using HMC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cdN3iKFT32Jp"
      },
      "source": [
        "Now that we've used TFD to specify our model and obtained some observed data, we have all the necessary pieces to run HMC.\n",
        "\n",
        "To do this, we'll use a [closure](https://en.wikipedia.org/wiki/Closure_(computer_programming%29#Anonymous_functions) to \"pin down\" the things we don't want to sample. In this case that means we need only pin down `observations`. (The hyper-parameters are already baked in to the prior distributions and not part of the `joint_log_prob` function signature.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "tVoaDFSf7L_j"
      },
      "outputs": [],
      "source": [
        "unnormalized_posterior_log_prob = lambda *args: joint_log_prob(observations, *args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "a0OMIWIYeMmQ"
      },
      "outputs": [],
      "source": [
        "initial_state = [\n",
        "    tf.fill([components],\n",
        "            value=np.array(1. / components, dtype),\n",
        "            name='mix_probs'),\n",
        "    tf.constant(np.array([[-2, -2],\n",
        "                          [0, 0],\n",
        "                          [2, 2]], dtype),\n",
        "                name='loc'),\n",
        "    tf.eye(dims, batch_shape=[components], dtype=dtype, name='chol_precision'),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TVpiT3LLyfcO"
      },
      "source": [
        "### Unconstrained Representation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JS8XOsxiyiBV"
      },
      "source": [
        "Hamiltonian Monte Carlo (HMC) requires the target log-probability function be differentiable with respect to its arguments.  Furthermore, HMC can exhibit dramatically higher statistical efficiency if the state-space is unconstrained.\n",
        "\n",
        "This means we'll have to work out two main issues when sampling from the BGMM posterior:\n",
        "\n",
        "1. $\\theta$ represents a discrete probability vector, i.e., must be such that $\\sum_{k=1}^K \\theta_k = 1$ and $\\theta_k\u003e0$.\n",
        "2. $T_k$ represents an inverse covariance matrix, i.e., must be such that $T_k \\succ 0$, i.e., is [positive definite](https://en.wikipedia.org/wiki/Positive-definite_matrix).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Vt9SXJzO0Cks"
      },
      "source": [
        "To address this requirement we'll need to:\n",
        "\n",
        "1. transform the constrained variables to an unconstrained space\n",
        "2. run the MCMC in unconstrained space\n",
        "3. transform the unconstrained variables back to the constrained space.\n",
        "\n",
        "As with `MVNCholPrecisionTriL`, we'll use [`Bijector`s](https://www.tensorflow.org/api_docs/python/tf/distributions/bijectors/Bijector) to transform random variables to unconstrained space.\n",
        "\n",
        "- The [`Dirichlet`](https://en.wikipedia.org/wiki/Dirichlet_distribution) is transformed to unconstrained space via the [softmax function](https://en.wikipedia.org/wiki/Softmax_function).\n",
        "\n",
        "- Our precision random variable is a distribution over postive semidefinite matrices. To unconstrain these we'll use the `FillTriangular` and `TransformDiagonal` bijectors.  These convert vectors to lower-triangular matrices and ensure the diagonal is positive. The former is useful because it enables sampling only $d(d+1)/2$ floats rather than $d^2$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "_atEQrDR7JvG"
      },
      "outputs": [],
      "source": [
        "unconstraining_bijectors = [\n",
        "    tfb.SoftmaxCentered(),\n",
        "    tfb.Identity(),\n",
        "    tfb.Chain([\n",
        "        tfb.TransformDiagonal(tfb.Softplus()),\n",
        "        tfb.FillTriangular(),\n",
        "    ])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "0zq6QJJ-NSPJ"
      },
      "outputs": [],
      "source": [
        "[mix_probs, loc, chol_precision], kernel_results = tfp.mcmc.sample_chain(\n",
        "    num_results=2000,\n",
        "    num_burnin_steps=500,\n",
        "    current_state=initial_state,\n",
        "    kernel=tfp.mcmc.TransformedTransitionKernel(\n",
        "        inner_kernel=tfp.mcmc.HamiltonianMonteCarlo(\n",
        "            target_log_prob_fn=unnormalized_posterior_log_prob,\n",
        "            step_size=0.064,\n",
        "            num_leapfrog_steps=5),\n",
        "        bijector=unconstraining_bijectors))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "_ceX1A3-ZFiN"
      },
      "outputs": [],
      "source": [
        "acceptance_rate = tf.reduce_mean(tf.to_float(kernel_results.inner_results.is_accepted))\n",
        "mean_mix_probs = tf.reduce_mean(mix_probs, axis=0)\n",
        "mean_loc = tf.reduce_mean(loc, axis=0)\n",
        "mean_chol_precision = tf.reduce_mean(chol_precision, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kmpTFZcVmByb"
      },
      "source": [
        "Note: through trial-and-error we've predetermined the `step_size` and `num_leapfrog_steps` to approximately achieve an [asymptotically optimal rate of 0.651](https://arxiv.org/abs/1001.4460). For a technique to do this automatically, see the examples section in `help(tfp.mcmc.HamiltonianMonteCarlo)`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QLEz96mg6fpZ"
      },
      "source": [
        "We'll now execute the chain and print the posterior means."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "colab_type": "code",
        "id": "3B2yJWVmNcrm"
      },
      "outputs": [],
      "source": [
        "[\n",
        "    acceptance_rate_,\n",
        "    mean_mix_probs_,\n",
        "    mean_loc_,\n",
        "    mean_chol_precision_,\n",
        "    mix_probs_,\n",
        "    loc_,\n",
        "    chol_precision_,\n",
        "] = sess.run([\n",
        "    acceptance_rate,\n",
        "    mean_mix_probs,\n",
        "    mean_loc,\n",
        "    mean_chol_precision,\n",
        "    mix_probs,\n",
        "    loc,\n",
        "    chol_precision,\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "height": 331
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 39,
          "status": "ok",
          "timestamp": 1529883683914,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "bqJ6RSJxegC6",
        "outputId": "7a28998f-2935-4890-f5bb-1a866bfe7ece"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    acceptance_rate: 0.679\n",
            "      avg mix probs: [ 0.37800151  0.27050072  0.35149774]\n",
            "\n",
            "            avg loc:\n",
            " [[-1.88035798 -1.80228877]\n",
            " [-0.02472795  0.01141072]\n",
            " [ 1.89979219  1.94372702]]\n",
            "\n",
            "avg chol(precision):\n",
            " [[[ 1.01998496  0.        ]\n",
            "  [-0.04656499  0.98116601]]\n",
            "\n",
            " [[ 1.20370901  0.        ]\n",
            "  [ 0.1873652   1.01483464]]\n",
            "\n",
            " [[ 0.99308145  0.        ]\n",
            "  [-0.11534245  0.97637659]]]\n"
          ]
        }
      ],
      "source": [
        "print('    acceptance_rate:', acceptance_rate_)\n",
        "print('      avg mix probs:', mean_mix_probs_)\n",
        "print('\\n            avg loc:\\n', mean_loc_)\n",
        "print('\\navg chol(precision):\\n', mean_chol_precision_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "height": 286
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 5287,
          "status": "ok",
          "timestamp": 1529883689326,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "zFOU0j9kPdUy",
        "outputId": "65570657-c550-4b77-dedc-07500d690fee"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAENCAYAAAASUO4dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nALAcIQcAyxFyALAcIQcAyxFyALDc/wEH8OM3L1VLYwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "\u003cmatplotlib.figure.Figure at 0x7ff1170d60d0\u003e"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "ax = sns.kdeplot(loc_[:,0,0], loc_[:,0,1], shade=True)\n",
        "ax = sns.kdeplot(loc_[:,1,0], loc_[:,1,1], shade=True)\n",
        "ax = sns.kdeplot(loc_[:,2,0], loc_[:,2,1], shade=True)\n",
        "plt.title('KDE of loc draws');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NmfNIM1c6mwc"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t8LeIeMn6ot4"
      },
      "source": [
        "This simple colab demonstrated how Tensorflow Probability primitives can be used to build hierarchical Bayesian mixture models."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "default_view": {},
      "name": "Bayesian_Gaussian_Mixture_Model.ipynb",
      "provenance": [
        {
          "file_id": "1rxhvVh5S5WeWnyEBHqTiH_z0oGZVSGyx",
          "timestamp": 1527714835004
        }
      ],
      "version": "0.3.2",
      "views": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
